{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planning / Scratch Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do /r/kpop commenters talk differently about male vs. female groups?\n",
    "\n",
    "Initial exploration of this question:\n",
    "- Identify submissions on 2 all-male groups, 2 all-female groups\n",
    "- Collect their comments\n",
    "- Contrast comments in general to \"typical\" reddit language (using /r/funny as a standard)\n",
    "- Contrast comments on male group vs female group "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Pushshift to get reddit comments\n",
    "\n",
    "See [Pushshift's GitHub API README](https://github.com/pushshift/api)\n",
    "\n",
    "> Search for the most recent comments mentioning the word \"science\" within the subreddit /r/askscience\n",
    ">\n",
    "> `https://api.pushshift.io/reddit/search/comment/?q=science&subreddit=askscience`\n",
    "\n",
    "Retrieve all comment ids for a submission object\n",
    "\n",
    "`https://api.pushshift.io/reddit/submission/comment_ids/{base36_submission_id}`\n",
    "\n",
    "[New to Pushshift FAQ](https://www.reddit.com/r/pushshift/comments/bcxguf/new_to_pushshift_read_this_faq/)\n",
    "\n",
    "[Pushshift Reddit API v4.0 Documentation](https://reddit-api.readthedocs.io/en/latest/#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not-comprehensive related works:\n",
    "- \"A Community of Curious Souls: An Analysis of Commenting Behavior on TED Talks Videos\" (Tsou, Thelwall, Mongeon, and Sugimoto, 2014)\n",
    "- \"YouTube science channel video presenters and comments: female friendly or vestiges of sexism?\" (Thelwall and Mas-Bleda, 2018)\n",
    "- \"Shirtless and dangerous: Quantifying linguistic signals of gender bias in an online fiction writing community.\" (Fast, Vachovsky, and Bernstein, 2016)\n",
    "- \"Using language models to quantify gender bias in sports journalism\" (Fu, Danescu-Niculescu-Mizil, Lee, 2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "ENGLISH_STOPWORDS = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect relevant /r/kpop submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = 'https://api.pushshift.io/reddit/search/submission/?subreddit=kpop&score=>50&num_comments=>50&size=100' # TODO: Collect more than 100 posts\n",
    "response = requests.get(url)\n",
    "post_titles = [post['title'] for post in response.json()['data']]\n",
    "post_ids = [post['id'] for post in response.json()['data']]\n",
    "post_id = post_ids[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the values that we can access for each submission?\n",
    "\n",
    "```\n",
    "response.json()['data'][1].keys()\n",
    "\n",
    "dict_keys(['all_awardings', 'allow_live_comments', 'author', 'author_flair_css_class', 'author_flair_richtext', 'author_flair_template_id', 'author_flair_text', \n",
    "'author_flair_text_color', 'author_flair_type', 'author_fullname', 'author_patreon_flair', 'author_premium', 'awarders', 'can_mod_post', 'contest_mode', 'created_utc', 'domain',\n",
    "'full_link', 'gildings', 'id', 'is_crosspostable', 'is_meta', 'is_original_content', 'is_reddit_media_domain', 'is_robot_indexable', 'is_self', 'is_video',\n",
    "'link_flair_background_color', 'link_flair_css_class', 'link_flair_richtext', 'link_flair_template_id', 'link_flair_text', 'link_flair_text_color', 'link_flair_type', 'locked',\n",
    "'media_only', 'no_follow', 'num_comments', 'num_crossposts', 'over_18', 'parent_whitelist_status', 'permalink', 'pinned', 'pwls', 'retrieved_on', 'score', 'selftext',\n",
    "'send_replies', 'spoiler', 'stickied', 'subreddit', 'subreddit_id', 'subreddit_subscribers', 'subreddit_type', 'thumbnail', 'title', 'total_awards_received', 'treatment_tags',\n",
    "'upvote_ratio', 'url', 'url_overridden_by_dest', 'whitelist_status', 'wls'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect comments given post_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = 'https://api.pushshift.io/reddit/comment/search?link_id=' + post_id\n",
    "response = requests.get(url, headers={'User-Agent': user_agent})\n",
    "comments_json = response.json()['data']\n",
    "comment_bodies = [comment['body'] for comment in comments_json]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the values that we can access for each comment?\n",
    "\n",
    "```python\n",
    "comments_json[0].keys()\n",
    "\n",
    "dict_keys(['all_awardings', 'approved_at_utc', 'associated_award', 'author', 'author_flair_background_color', 'author_flair_css_class', 'author_flair_richtext',\n",
    "'author_flair_template_id', 'author_flair_text', 'author_flair_text_color', 'author_flair_type', 'author_fullname', 'author_patreon_flair', 'author_premium', 'awarders',\n",
    "'banned_at_utc', 'body', 'can_mod_post', 'collapsed', 'collapsed_because_crowd_control', 'collapsed_reason', 'created_utc', 'distinguished', 'edited', 'gildings', 'id', \n",
    "'is_submitter', 'link_id', 'locked', 'no_follow', 'parent_id', 'permalink', 'retrieved_on', 'score', 'send_replies', 'stickied', 'subreddit', 'subreddit_id', 'top_awarded_type', \n",
    "'total_awards_received', 'treatment_tags'])\n",
    "   \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for i, post_id in enumerate(post_ids):\n",
    "    url = 'https://api.pushshift.io/reddit/comment/search?link_id=' + post_id # TODO: Collect more than 25 comments per post\n",
    "    response = requests.get(url, headers={'User-Agent': user_agent})\n",
    "    comments_json = response.json()['data']\n",
    "    comment_bodies = [comment['body'] for comment in comments_json]\n",
    "    entry = [post_id, post_titles[i], comment_bodies]\n",
    "    data.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame(data, columns=['id', 'title', 'comments'])\n",
    "data_df.to_csv('rkpop-data.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify male vs female groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "m_f_mapping = {'male': {'EXO', 'NCT', 'BTS', 'Stray Kids', 'G-Dragon', 'Big Bang', \n",
    "                        'AB6IX', 'Golden Child', 'SEVENTEEN', 'Top Secret', 'TST', \n",
    "                        'ONEUS', 'TVXQ', 'PENTAGON', 'THE BOYZ', 'VERIVERY', 'Ravi', 'WayV', 'VIXX'},\n",
    "               'female': {'GFriend', \"Girl's Day\", 'Red Velvet', 'AOA', 'BLACKPINK', \n",
    "               'Momoland', 'miss A', 'MAMAMOO', 'ITZY', 'Sunmi', 'Weeekly', 'NiziU', \n",
    "               'NATTY', 'Twice', 'LOONA', 'After School', 'IU', 'IZ*ONE', 'WJSN', \n",
    "               'Cosmic Girls', 'DIA', 'CHUNGHA'}\n",
    "}\n",
    "m_f_mapping['male'] = {g.lower() for g in m_f_mapping['male']}\n",
    "m_f_mapping['female'] = {g.lower() for g in m_f_mapping['female']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tag submissions with male or female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Count a submission as 'male' or 'female' only if it has one gender present?\n",
    "data_df['male'] = data_df.title.apply(lambda t: any(group in t.lower() for group in m_f_mapping['male']))\n",
    "data_df['female'] = data_df.title.apply(lambda t: any(group in t.lower() for group in m_f_mapping['female']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [id, title, comments, male, female]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>comments</th>\n      <th>male</th>\n      <th>female</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 269
    }
   ],
   "source": [
    "# Checking if any overlapping...\n",
    "data_df[data_df['male'] & data_df['female']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean comment text and prepare for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[How to strip punctuation from a string](https://stackoverflow.com/questions/265960/best-way-to-strip-punctuation-from-a-string)\n",
    "\n",
    "`s.translate(str.maketrans('', '', string.punctuation))`\n",
    "\n",
    "[`maketrans` documentation](https://docs.python.org/3.3/library/stdtypes.html?highlight=maketrans#str.maketrans)\n",
    "\n",
    "[Removing URLs from a string](https://stackoverflow.com/questions/11331982/how-to-remove-any-url-within-a-string-in-python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def giant_cleaned_string(series_of_list_of_comments):\n",
    "    \"\"\"Return string from Pandas Series of lists of strings.\n",
    "    \n",
    "    Combines multiple pandas rows with lists of strings into one giant string with URLs and punctuation removed.\n",
    "    \"\"\"\n",
    "    comment_string = ' '.join(series_of_list_of_comments.apply(lambda x: ' '.join(x)))\n",
    "    comment_string = re.sub('http://\\S+|https://\\S+', '', comment_string)\n",
    "\n",
    "    chars_to_replace = string.punctuation[:6]+string.punctuation[7:]+'“”\\n' # Don't remove single quotation mark\n",
    "    whitespace_to_replace_with = len(chars_to_replace) * ' '\n",
    "\n",
    "    comment_string = comment_string.lower().translate(str.maketrans(chars_to_replace, whitespace_to_replace_with))\n",
    "    return comment_string\n",
    "\n",
    "def acceptable_token(token):\n",
    "    \"\"\" Return True if token is longer than one character and is not present in ENGLISH_STOPWORDS\n",
    "    \"\"\"\n",
    "    return (len(token) > 1 and token not in ENGLISH_STOPWORDS)\n",
    "\n",
    "def tokenize(giant_comment_string):\n",
    "    \"\"\" Return list of word tokens from given string.\n",
    "    \"\"\"\n",
    "    tokens = giant_comment_string.split(' ')\n",
    "    return list(filter(acceptable_token, tokens))\n",
    "\n",
    "def create_counter_object(giant_comment_string):\n",
    "    \"\"\" Return Counter with word counters for given string.\n",
    "    \"\"\"\n",
    "    word_counter = Counter(tokenize(giant_comment_string))\n",
    "    return word_counter\n",
    "\n",
    "def top_adjectives(giant_comment_string, num_of_words=10):\n",
    "    \"\"\" Return list with most common adjectives in given string.\n",
    "    \"\"\"\n",
    "\n",
    "    def find_adjectives(list_of_word_pos_tuple):\n",
    "        return list_of_word_pos_tuple[1] == 'JJ'\n",
    "\n",
    "    comment_words_POS = nltk.pos_tag(tokenize(giant_comment_string))\n",
    "    comment_adj_counter = Counter([adj[0] for adj in list(filter(find_adjectives, comment_words_POS))])\n",
    "    return comment_adj_counter.most_common(num_of_words)\n",
    "\n",
    "# TODO: Determine association metric to use\n",
    "# http://www.nltk.org/_modules/nltk/metrics/association.html\n",
    "def top_ngrams(giant_comment_string, num_of_words=15, ngram=2):\n",
    "    \"\"\" Return list with most frequently appearing n-grams in given string.\n",
    "    \"\"\"\n",
    "\n",
    "    if ngram == 2:\n",
    "        finder = BigramCollocationFinder.from_words(tokenize(giant_comment_string))\n",
    "        return finder.nbest(bigram_measures.likelihood_ratio, num_of_words)\n",
    "    elif ngram == 3:\n",
    "        finder = TrigramCollocationFinder.from_words(tokenize(giant_comment_string))\n",
    "        return finder.nbest(trigram_measures.likelihood_ratio, num_of_words)\n",
    "    else:\n",
    "        return \"Error: Only bi- and trigrams supported.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_giant_comment_string = giant_cleaned_string(data_df[data_df['male']]['comments'])\n",
    "female_giant_comment_string = giant_cleaned_string(data_df[data_df['female']]['comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_word_counter = create_counter_object(female_giant_comment_string)\n",
    "male_word_counter = create_counter_object(male_giant_comment_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Log-Odds Ratio of Words\n",
    "# len(male_giant_comment_string.split(' ')) # 6718 \n",
    "# len(female_giant_comment_string.split(' ')) # 14882"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "male_top_50 = male_word_counter.most_common(50)\n",
    "female_top_50 = female_word_counter.most_common(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What adjectives are used? Verbs? \n",
    "\n",
    "[Categorizing and Tagging Words](https://www.nltk.org/book/ch05.html)\n",
    "\n",
    "[collocations](https://www.nltk.org/howto/collocations.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most common ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.collocations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('city', 'pop', 'real'),\n ('city', 'pop', 'icing'),\n ('city', 'pop', 'influence'),\n ('city', 'pop', 'permit'),\n ('sucker', 'city', 'pop'),\n ('city', 'pop', 'catch'),\n ('city', 'pop', 'lately'),\n ('city', 'pop', 'term'),\n ('considered', 'city', 'pop'),\n ('fall', 'city', 'pop'),\n ('siren', 'city', 'pop'),\n ('sounding', 'city', 'pop'),\n ('term', 'city', 'pop'),\n ('ton', 'city', 'pop'),\n ('defend', 'city', 'pop'),\n ('game', 'city', 'pop'),\n ('using', 'city', 'pop'),\n ('red', 'velvet', 'leaders'),\n ('😄😆', 'red', 'velvet'),\n ('example', 'city', 'pop'),\n ('hear', 'city', 'pop'),\n ('quite', 'city', 'pop'),\n ('call', 'city', 'pop'),\n ('city', 'pop', 'like'),\n ('red', 'velvet', 'listener'),\n ('need', 'city', 'pop'),\n ('city', 'pop', 'excited'),\n ('casual', 'red', 'velvet'),\n ('perhaps', 'red', 'velvet'),\n ('red', 'velvet', 'oldest'),\n ('irene', 'red', 'velvet'),\n ('city', 'pop', 'well'),\n ('city', 'pop', 'even'),\n ('expecting', 'red', 'velvet'),\n ('red', 'velvet', 'promote'),\n ('red', 'velvet', 'stick'),\n ('snsd', 'red', 'velvet'),\n ('red', 'velvet', 'dumb'),\n ('city', 'pop', \"i'm\"),\n ('city', 'pop', 'really'),\n ('red', 'velvet', 'lead'),\n ('red', 'velvet', 'vs'),\n ('comment', 'red', 'velvet'),\n ('industry', 'red', 'velvet'),\n ('use', 'red', 'velvet'),\n ('agree', 'red', 'velvet'),\n ('red', 'velvet', 'genre'),\n ('red', 'velvet', 'excited'),\n ('love', 'red', 'velvet'),\n ('red', 'velvet', 'members')]"
     },
     "metadata": {},
     "execution_count": 336
    }
   ],
   "source": [
    "top_ngrams(female_giant_comment_string, num_of_words=50, ngram=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('defending', 'stray', 'kids'),\n ('discussion', 'stray', 'kids'),\n ('familiar', 'stray', 'kids'),\n ('perception', 'stray', 'kids'),\n ('stray', 'kids', 'crackhead'),\n ('stray', 'kids', 'draws'),\n ('stray', 'kids', 'objectively'),\n ('stray', 'kids', 'touring'),\n ('stray', 'kids', 'specifically'),\n ('opinion', 'stray', 'kids'),\n ('stray', 'kids', 'called'),\n ('stray', 'kids', 'marketed'),\n ('blm', 'stray', 'kids'),\n ('point', 'stray', 'kids'),\n ('stray', 'kids', 'group'),\n ('groups', 'stray', 'kids'),\n ('love', 'stray', 'kids'),\n ('stray', 'kids', 'would'),\n ('culture', 'stray', 'kids'),\n ('stray', 'kids', \"i'm\"),\n ('hip', 'hop', 'rap'),\n ('features', 'hip', 'hop'),\n ('hoping', 'hip', 'hop'),\n ('consider', 'hip', 'hop'),\n ('hip', 'hop', 'banger'),\n ('american', 'hip', 'hop'),\n ('hip', 'hop', 'pop'),\n ('also', 'hip', 'hop'),\n ('find', 'new', 'home'),\n ('pretty', 'much', 'contained'),\n ('almost', 'pretty', 'much'),\n ('bans', 'depending', 'severity'),\n ('concert', 'entails', 'proper'),\n ('entails', 'proper', 'guidelines'),\n ('permanent', 'bans', 'depending'),\n ('temporary', 'permanent', 'bans'),\n ('also', 'discussed', 'posibble'),\n ('guidelines', 'also', 'discussed'),\n ('present', 'also', 'discussed'),\n ('guys', 'really', 'insensitive'),\n ('exo', 'sc', 'possibe'),\n ('opposite', 'exo', 'sc'),\n ('teamin', 'exo', 'sc'),\n ('heavily', 'black', 'culture'),\n ('depending', 'severity', 'actions'),\n ('hurl', 'meaningless', 'insults'),\n ('launch', 'search', 'party'),\n ('lived', 'western', 'countries'),\n ('please', 'continue', 'showing'),\n ('action', 'temporary', 'permanent')]"
     },
     "metadata": {},
     "execution_count": 338
    }
   ],
   "source": [
    "top_ngrams(male_giant_comment_string, num_of_words=50, ngram=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most common adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('good', 46),\n ('much', 39),\n ('new', 37),\n ('different', 35),\n ('korean', 32),\n ('many', 25),\n (\"i'm\", 24),\n ('bad', 23),\n ('japanese', 19),\n ('similar', 18),\n ('english', 18),\n ('first', 17),\n ('last', 17),\n ('happy', 16),\n ('great', 16),\n ('big', 16),\n ('lol', 15),\n ('it’s', 15),\n ('right', 15),\n ('sure', 15),\n ('full', 14),\n ('favorite', 13),\n ('single', 13),\n ('whole', 12),\n ('weird', 12),\n ('little', 12),\n ('wrong', 11),\n ('amazing', 11),\n ('real', 11),\n ('american', 11),\n ('popular', 11),\n ('long', 11),\n ('high', 11),\n ('red', 10),\n ('international', 10),\n ('sad', 10),\n ('top', 10),\n ('ready', 10),\n ('cute', 9),\n ('hard', 9),\n ('i’m', 9),\n ('mean', 9),\n ('main', 8),\n ('original', 8),\n ('give', 8),\n ('western', 8),\n ('song', 8),\n ('stupid', 7),\n ('aware', 7),\n (\"that's\", 7)]"
     },
     "metadata": {},
     "execution_count": 335
    }
   ],
   "source": [
    "most_common_adjectives(female_giant_comment_string, n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('much', 26),\n ('black', 22),\n ('happy', 19),\n ('new', 16),\n (\"i'm\", 15),\n ('western', 13),\n ('different', 12),\n ('sure', 12),\n ('american', 12),\n ('korean', 12),\n ('good', 11),\n ('last', 11),\n ('big', 11),\n ('old', 11),\n ('many', 10),\n ('first', 10),\n ('great', 10),\n ('right', 9),\n (\"that's\", 9),\n ('little', 8),\n ('open', 8),\n ('wrong', 7),\n ('whole', 6),\n ('long', 6),\n ('it’s', 6),\n ('cultural', 6),\n ('live', 6),\n ('sm', 6),\n ('asian', 6),\n ('clear', 6),\n ('bad', 6),\n ('i’m', 5),\n ('hard', 5),\n ('specific', 5),\n ('bts', 5),\n ('shit', 5),\n ('likely', 5),\n ('exo', 4),\n ('next', 4),\n ('proud', 4),\n ('iconic', 4),\n ('amazing', 4),\n ('true', 4),\n (\"can't\", 4),\n ('nct', 4),\n ('anniversary', 4),\n ('thank', 4),\n ('nice', 4),\n ('huge', 4),\n ('fair', 4)]"
     },
     "metadata": {},
     "execution_count": 334
    }
   ],
   "source": [
    "most_common_adjectives(male_giant_comment_string, n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1594445694617",
   "display_name": "Python 3.8.3 64-bit ('gendered-discussion': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}