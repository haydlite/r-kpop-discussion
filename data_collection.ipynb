{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planning / Scratch Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do /r/kpop commenters talk differently about male vs. female groups?\n",
    "\n",
    "Initial exploration of this question:\n",
    "- Identify submissions on 2 all-male groups, 2 all-female groups\n",
    "- Collect their comments\n",
    "- Contrast comments in general to \"typical\" reddit language (using /r/funny as a standard)\n",
    "- Contrast comments on male group vs female group "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Maybe separate analysis for emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Pushshift to get reddit comments\n",
    "\n",
    "See [Pushshift's GitHub API README](https://github.com/pushshift/api)\n",
    "\n",
    "> Search for the most recent comments mentioning the word \"science\" within the subreddit /r/askscience\n",
    ">\n",
    "> `https://api.pushshift.io/reddit/search/comment/?q=science&subreddit=askscience`\n",
    "\n",
    "Retrieve all comment ids for a submission object\n",
    "\n",
    "`https://api.pushshift.io/reddit/submission/comment_ids/{base36_submission_id}`\n",
    "\n",
    "[New to Pushshift FAQ](https://www.reddit.com/r/pushshift/comments/bcxguf/new_to_pushshift_read_this_faq/)\n",
    "\n",
    "[Pushshift Reddit API v4.0 Documentation](https://reddit-api.readthedocs.io/en/latest/#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not-comprehensive related works:\n",
    "- \"A Community of Curious Souls: An Analysis of Commenting Behavior on TED Talks Videos\" (Tsou, Thelwall, Mongeon, and Sugimoto, 2014)\n",
    "- \"YouTube science channel video presenters and comments: female friendly or vestiges of sexism?\" (Thelwall and Mas-Bleda, 2018)\n",
    "- \"Shirtless and dangerous: Quantifying linguistic signals of gender bias in an online fiction writing community.\" (Fast, Vachovsky, and Bernstein, 2016)\n",
    "- \"Using language models to quantify gender bias in sports journalism\" (Fu, Danescu-Niculescu-Mizil, Lee, 2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import requests\n",
    "import logging\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "ENGLISH_STOPWORDS = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pushshift Notes\n",
    "\n",
    "What are the values that we can access for each submission?\n",
    "\n",
    "```python\n",
    "> response.json()['data'][1].keys()\n",
    "\n",
    "> dict_keys(['all_awardings', 'allow_live_comments', 'author', 'author_flair_css_class', 'author_flair_richtext', 'author_flair_template_id', 'author_flair_text', \n",
    "'author_flair_text_color', 'author_flair_type', 'author_fullname', 'author_patreon_flair', 'author_premium', 'awarders', 'can_mod_post', 'contest_mode', 'created_utc', 'domain',\n",
    "'full_link', 'gildings', 'id', 'is_crosspostable', 'is_meta', 'is_original_content', 'is_reddit_media_domain', 'is_robot_indexable', 'is_self', 'is_video',\n",
    "'link_flair_background_color', 'link_flair_css_class', 'link_flair_richtext', 'link_flair_template_id', 'link_flair_text', 'link_flair_text_color', 'link_flair_type', 'locked',\n",
    "'media_only', 'no_follow', 'num_comments', 'num_crossposts', 'over_18', 'parent_whitelist_status', 'permalink', 'pinned', 'pwls', 'retrieved_on', 'score', 'selftext',\n",
    "'send_replies', 'spoiler', 'stickied', 'subreddit', 'subreddit_id', 'subreddit_subscribers', 'subreddit_type', 'thumbnail', 'title', 'total_awards_received', 'treatment_tags',\n",
    "'upvote_ratio', 'url', 'url_overridden_by_dest', 'whitelist_status', 'wls'])\n",
    "```\n",
    "\n",
    "Note that `created_utc` is given in unix timestamp\n",
    "\n",
    "```\n",
    "> [post['created_utc'] for post in response.json()['data']]\n",
    "\n",
    ">[1595657105,\n",
    " 1595641997,\n",
    " 1595632191,\n",
    " 1595623051,\n",
    " 1595602847,\n",
    " 1595599200,\n",
    " 1595583205,\n",
    " 1595581926,...\n",
    "```\n",
    "\n",
    "This tells us that newer posts are given first (i.e. order of posts in repsonse.json() is newest to oldest).\n",
    "\n",
    "What are the values that we can access for each comment?\n",
    "\n",
    "```python\n",
    "comments_json[0].keys()\n",
    "\n",
    "dict_keys(['all_awardings', 'approved_at_utc', 'associated_award', 'author', 'author_flair_background_color', 'author_flair_css_class', 'author_flair_richtext',\n",
    "'author_flair_template_id', 'author_flair_text', 'author_flair_text_color', 'author_flair_type', 'author_fullname', 'author_patreon_flair', 'author_premium', 'awarders',\n",
    "'banned_at_utc', 'body', 'can_mod_post', 'collapsed', 'collapsed_because_crowd_control', 'collapsed_reason', 'created_utc', 'distinguished', 'edited', 'gildings', 'id', \n",
    "'is_submitter', 'link_id', 'locked', 'no_follow', 'parent_id', 'permalink', 'retrieved_on', 'score', 'send_replies', 'stickied', 'subreddit', 'subreddit_id', 'top_awarded_type', \n",
    "'total_awards_received', 'treatment_tags'])\n",
    "   \n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect 1000 posts\n",
    "posts = []\n",
    "oldest_post_id = None\n",
    "while len(posts) < 1000:\n",
    "    if oldest_post_id is None:\n",
    "        posts.extend(collect_posts())\n",
    "    else:\n",
    "        post.extend(collect_posts(oldest_post_id))\n",
    "\n",
    "save_data(posts, 'data/rkpop-1000-posts.pkl')\n",
    "# test_load = load_data('rkpop-1000-posts.pkl')\n",
    "# assert test_load == posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "\n",
    "num_cpu = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_collection_utils import collect_comment, load_data, save_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = load_data('data/rkpop-1000-posts.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with Pool(10) as p:\n",
    "    comments = p.map(collect_comment, posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(comments, 'data/rkpop-1000-comments.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for comment_pkl in glob.glob('data/comments/*'):\n",
    "#     print(len(load_data(comment_pkl))) \n",
    "# ??? Some sort f collection error... fewer than 50 for many"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = {}\n",
    "for filename in glob.glob('data/comments/*'):\n",
    "    start = filename.rindex('/') + 1\n",
    "    end = filename.rindex('-')\n",
    "    post_id = filename[start:end]\n",
    "    comments[post_id] = load_data(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(comments, 'data/rkpop-3000-comments.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "dict_keys(['huclsf', 'htuc60', 'hvskyu', 'hucjmo', 'hu9rcu', 'huzmb5', 'hwtrm6', 'hrp506', 'hv2356', 'ho4kpi', 'hu3597', 'huu5n2', 'huvuwp', 'hu7vo3', 'hvtdw0', 'hv1ebo', 'huzsvw', 'hqyxzz', 'hrc8b0', 'hrljep', 'hub1jr', 'hvj3uw', 'hvka7v', 'hvj615', 'hudp5x', 'htybex', 'hx29od', 'hw0msh', 'huxala', 'hudowa', 'hrp4jz', 'hv8u2z', 'hxc2tq', 'hv422q', 'hxhvbk', 'hudxp1', 'hvvai2', 'htpot9', 'hvvasx', 'hwyk30', 'hu5qlw', 'hv41za', 'humrj9', 'hx3a8s', 'hvrr9j', 'hvqe4a', 'hub3bl', 'hvqpny', 'hui3wc', 'htvhtn', 'hvvaiq', 'hvs5o0', 'huoafl', 'hudqes', 'hx9kq3', 'hv7a2v', 'hrfis5', 'hubz5p', 'hxekwy', 'hv1n7f', 'husgf7', 'humrtx', 'hujyqp', 'hwg5tm', 'hu0d49', 'hvt82o', 'htujl0', 'hr34w6', 'hv4vrd'])"
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "comments.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_ids = [p['id'] for p in posts]\n",
    "post_titles = [p['title'] for p in posts]\n",
    "\n",
    "post_ids_titles_dict = dict(zip(post_ids, post_titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[\"BTS ISN'T THAT GOOD, THEY LOOK GAY\",\n \"I'm really just venting/ranting because people were responsible for the safety of that stage, but failed to do their job. This could be career-altering and life-changing. They ruined this year for her and potentially limited her career.\\n\\nLike I said, it's good that she's recovering well. We all knew from the beginning that she would recover. It's the uncertainty after recovery that I'm worried about. It just might be too troublesome continue her career after because injuries can have lasting effects on the human body long after recovery. No young person should have to deal with that.\",\n \"Can I just clarify that my original post meant that they got away with allowing for a dangerous set up in the first place? The injury should never have occurred and i find it really bizarre that defending SBS seems to be the hill that you're wanting to die on. I'm just expressing my frustrations that such shitty working environments are created for idols in the first place, let alone all the other crap they go through. I don't really care about the extent of the compensation that they would offer only that even if they were to comprehensively cover her fees and loss of profits, it'd be the bare minimum for the injury that she sustained whilst performing there.\\n\\nI can't imagine why you're interested in still contesting this apart from either bring a #hailcorporate type or a contrarian for the sake of it. I'm not going continue aruging why I am allowed to be angry at SBS for their negligence.\",\n \"&gt; I'm not completely up to speed on how they've handled it but I haven't seen much from SBS apart from their initial mismanagement, the police investigation and supposedly them providing some compensation for medical costs.\\n\\nBecause they aren't going to make shit like that public. This stuff is nearly always handled behind closed doors to make it easier on everyone involved, including Wendy.\\n\\n&gt; I'm just angry/concerned for Wendy because so often it's the individual who gets screwed over by large companies due to things like work injuries and hazards\\n\\nMy entire point is we don't actually know that as most of the time these things aren't public. We can only assume\",\n 'Most Reveluvs did that because there was no information about her injuries earlier on. Your concern is valid, but all over this thread you have been painting it as a definite, 100% thing, when it is pure speculation.']"
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "comments['huclsf'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['definitely, i was so sad to see them not make it far :(',\n \"and the best group on that show but we're not ready for that conversation yet\",\n 'Oh yeah, Bomin is definitely helping their group get recognized but I think a good chunk of people don‚Äôt even know he‚Äôs an idol because he‚Äôs so good at acting!',\n \"Yess, my boys deserve even more success! I've been following them since their Let Me comeback and there isn't really a song I didn't like from them (but Crush is still my favorite)!\\nGo GolCha!\",\n \"They really worked so hard for this promotion I'm so so happy to see this, they've suffered so much through 2019 because of the hiatus and then seeing them crying on that circus show made my heart break again but I'm happy that they've left those memories behind and seem happier these days. Realise how golcha has never mentioned RTK at all since leaving that shit lmao\"]"
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "comments['htuc60'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "dict_keys(['huclsf', 'htuc60', 'hvskyu', 'hucjmo', 'hu9rcu', 'huzmb5', 'hwtrm6', 'hrp506', 'hv2356', 'ho4kpi', 'hu3597', 'huu5n2', 'huvuwp', 'hu7vo3', 'hvtdw0', 'hv1ebo', 'huzsvw', 'hqyxzz', 'hrc8b0', 'hrljep', 'hub1jr', 'hvj3uw', 'hvka7v', 'hvj615', 'hudp5x', 'htybex', 'hx29od', 'hw0msh', 'huxala', 'hudowa', 'hrp4jz', 'hv8u2z', 'hxc2tq', 'hv422q', 'hxhvbk', 'hudxp1', 'hvvai2', 'htpot9', 'hvvasx', 'hwyk30', 'hu5qlw', 'hv41za', 'humrj9', 'hx3a8s', 'hvrr9j', 'hvqe4a', 'hub3bl', 'hvqpny', 'hui3wc', 'htvhtn', 'hvvaiq', 'hvs5o0', 'huoafl', 'hudqes', 'hx9kq3', 'hv7a2v', 'hrfis5', 'hubz5p', 'hxekwy', 'hv1n7f', 'husgf7', 'humrtx', 'hujyqp', 'hwg5tm', 'hu0d49', 'hvt82o', 'htujl0', 'hr34w6', 'hv4vrd'])"
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "comments.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading from saved CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     index                                                  0\n0   hxhvbk  Mamamoo Wheein - Candy (orig. Baekhyun) (Speci...\n1   hxekwy  Red Velvet - IRENE &amp; SEULGI - Monster (Two...\n2   hxc2tq  BLACKPINK Lisa Appointed as Ambassador for BVL...\n3   hx9kq3  The Rolling Stone included 9 K-Pop Boygroup so...\n4   hx3a8s  PURPLE K!SS - Debut Trailer : WH0 CARES? - Ïú†ÌÇ§ ...\n..     ...                                                ...\n95  ho4kzo             EXO-SC - On Me (Sehun Solo - Track MV)\n96  ho4kpi                      GFriend - Apple (MV Teaser 1)\n97  hnin4k              Happy 10th Anniversary to Girl's Day!\n98  hm9ctk                  Happy 4th anniversary to NCT 127!\n99  hm9cak  Red Velvet - IRENE &amp; SEULGI - Monster Musi...\n\n[100 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>hxhvbk</td>\n      <td>Mamamoo Wheein - Candy (orig. Baekhyun) (Speci...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>hxekwy</td>\n      <td>Red Velvet - IRENE &amp;amp; SEULGI - Monster (Two...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>hxc2tq</td>\n      <td>BLACKPINK Lisa Appointed as Ambassador for BVL...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>hx9kq3</td>\n      <td>The Rolling Stone included 9 K-Pop Boygroup so...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>hx3a8s</td>\n      <td>PURPLE K!SS - Debut Trailer : WH0 CARES? - Ïú†ÌÇ§ ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>ho4kzo</td>\n      <td>EXO-SC - On Me (Sehun Solo - Track MV)</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>ho4kpi</td>\n      <td>GFriend - Apple (MV Teaser 1)</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>hnin4k</td>\n      <td>Happy 10th Anniversary to Girl's Day!</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>hm9ctk</td>\n      <td>Happy 4th anniversary to NCT 127!</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>hm9cak</td>\n      <td>Red Velvet - IRENE &amp;amp; SEULGI - Monster Musi...</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows √ó 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments_from_obj(post_id):\n",
    "    if post_id in comments:\n",
    "        return comments[post_id]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        id                                              title  \\\n0   hxhvbk  Mamamoo Wheein - Candy (orig. Baekhyun) (Speci...   \n1   hxekwy  Red Velvet - IRENE &amp; SEULGI - Monster (Two...   \n2   hxc2tq  BLACKPINK Lisa Appointed as Ambassador for BVL...   \n3   hx9kq3  The Rolling Stone included 9 K-Pop Boygroup so...   \n4   hx3a8s  PURPLE K!SS - Debut Trailer : WH0 CARES? - Ïú†ÌÇ§ ...   \n..     ...                                                ...   \n95  ho4kzo             EXO-SC - On Me (Sehun Solo - Track MV)   \n96  ho4kpi                      GFriend - Apple (MV Teaser 1)   \n97  hnin4k              Happy 10th Anniversary to Girl's Day!   \n98  hm9ctk                  Happy 4th anniversary to NCT 127!   \n99  hm9cak  Red Velvet - IRENE &amp; SEULGI - Monster Musi...   \n\n                                             comments  \n0   [I'm so happy she didn't change the pronouns, ...  \n1   [RV never ever created a bad song, let alone a...  \n2   [count me in, what about Hera?, anyone partner...  \n3   [Lol @ the strawman, Man I'm reading through t...  \n4   [Yes Indeed, it\\`s a classic produce thing whe...  \n..                                                ...  \n95                                               None  \n96  [Obvious girl detected, lol. Gfriend is for me...  \n97                                               None  \n98                                               None  \n99                                               None  \n\n[100 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>comments</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>hxhvbk</td>\n      <td>Mamamoo Wheein - Candy (orig. Baekhyun) (Speci...</td>\n      <td>[I'm so happy she didn't change the pronouns, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>hxekwy</td>\n      <td>Red Velvet - IRENE &amp;amp; SEULGI - Monster (Two...</td>\n      <td>[RV never ever created a bad song, let alone a...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>hxc2tq</td>\n      <td>BLACKPINK Lisa Appointed as Ambassador for BVL...</td>\n      <td>[count me in, what about Hera?, anyone partner...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>hx9kq3</td>\n      <td>The Rolling Stone included 9 K-Pop Boygroup so...</td>\n      <td>[Lol @ the strawman, Man I'm reading through t...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>hx3a8s</td>\n      <td>PURPLE K!SS - Debut Trailer : WH0 CARES? - Ïú†ÌÇ§ ...</td>\n      <td>[Yes Indeed, it\\`s a classic produce thing whe...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>ho4kzo</td>\n      <td>EXO-SC - On Me (Sehun Solo - Track MV)</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>ho4kpi</td>\n      <td>GFriend - Apple (MV Teaser 1)</td>\n      <td>[Obvious girl detected, lol. Gfriend is for me...</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>hnin4k</td>\n      <td>Happy 10th Anniversary to Girl's Day!</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>hm9ctk</td>\n      <td>Happy 4th anniversary to NCT 127!</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>hm9cak</td>\n      <td>Red Velvet - IRENE &amp;amp; SEULGI - Monster Musi...</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows √ó 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(post_ids_titles_dict, orient='index')\n",
    "comments_as_series = df.reset_index()['index'].apply(lambda post_id: get_comments_from_obj(post_id))\n",
    "df = df.reset_index()\n",
    "df['comments'] = comments_as_series\n",
    "df.columns = ['id', 'title', 'comments']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/rkpop-data-2020-08-01.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('data/rkpop-data-2020-08-01.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify male vs female groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m_f_mapping = {'male': {'EXO', 'NCT', 'BTS', 'Stray Kids', 'G-Dragon', 'Big Bang', \n",
    "                        'AB6IX', 'Golden Child', 'SEVENTEEN', 'Top Secret', 'TST', \n",
    "                        'ONEUS', 'TVXQ', 'PENTAGON', 'THE BOYZ', 'VERIVERY', 'Ravi', \n",
    "                        'WayV', 'VIXX', 'Super Junior', 'SHINee', 'Monsta X',\n",
    "                        'Block B', 'Zico', 'Treasure'},\n",
    "\n",
    "               'female': {'GFriend', \"Girl's Day\", 'Red Velvet', 'AOA', 'BLACKPINK', \n",
    "               'Momoland', 'miss A', 'MAMAMOO', 'ITZY', 'Sunmi', 'Weeekly', 'NiziU', \n",
    "               'NATTY', 'Twice', 'LOONA', 'After School', 'IU', 'IZ*ONE', 'WJSN', \n",
    "               'Cosmic Girls', 'DIA', 'CHUNGHA', 'SNSD', 'Cherry Bullet', 'Somi', \n",
    "               '(G)I-DLE', 'Apink', 'Yukika', 'Oh My Girl', 'Lee Hi',\n",
    "               'PURPLE K!SS', 'Singer Minty', 'Rocket Punch'}\n",
    "}\n",
    "m_f_mapping['male'] = {g.lower() for g in m_f_mapping['male']}\n",
    "m_f_mapping['female'] = {g.lower() for g in m_f_mapping['female']}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tag submissions with male or female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        id                                              title comments  male  \\\n85  hrc2pf  EXO-SC, MAMAMOO, Red Velvet Irene &amp; Seulgi...      NaN  True   \n\n    female  \n85    True  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>comments</th>\n      <th>male</th>\n      <th>female</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>85</th>\n      <td>hrc2pf</td>\n      <td>EXO-SC, MAMAMOO, Red Velvet Irene &amp;amp; Seulgi...</td>\n      <td>NaN</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 151
    }
   ],
   "source": [
    "# Checking if any overlapping...\n",
    "data_df[data_df['male'] & data_df['female']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Count a submission as 'male' or 'female' only if it has one gender present?\n",
    "data_df['male'] = data_df['title'].apply(lambda t: any(group in t.lower() for group in m_f_mapping['male']))\n",
    "data_df['female'] = data_df['title'].apply(lambda t: any(group in t.lower() for group in m_f_mapping['female']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean comment text and prepare for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "59\n"
    }
   ],
   "source": [
    "data_df_subset = data_df[((data_df['male']) | (data_df['female'])) & data_df['comments']] # Keep only comments w either male or female TRUE & comments are available\n",
    "data_df_subset = data_df_subset[ ~(data_df_subset['male'] & data_df_subset['female']) ] # Removes overlapping\n",
    "print(len(data_df_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[How to strip punctuation from a string](https://stackoverflow.com/questions/265960/best-way-to-strip-punctuation-from-a-string)\n",
    "\n",
    "`s.translate(str.maketrans('', '', string.punctuation))`\n",
    "\n",
    "[`maketrans` documentation](https://docs.python.org/3.3/library/stdtypes.html?highlight=maketrans#str.maketrans)\n",
    "\n",
    "[Removing URLs from a string](https://stackoverflow.com/questions/11331982/how-to-remove-any-url-within-a-string-in-python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def giant_cleaned_string(series_of_list_of_comments):\n",
    "    \"\"\"Return string from Pandas Series of lists of strings.\n",
    "    \n",
    "    Combines multiple pandas rows with lists of strings into one giant string with URLs and punctuation removed.\n",
    "    \"\"\"\n",
    "    comment_string = ' '.join(series_of_list_of_comments.apply(lambda x: ' '.join(x.split())))\n",
    "    comment_string = re.sub('http://\\S+|https://\\S+', '', comment_string)\n",
    "\n",
    "    chars_to_replace = string.punctuation[:6]+string.punctuation[7:]+'‚Äú‚Äù\\n' # Don't remove single quotation mark\n",
    "    whitespace_to_replace_with = len(chars_to_replace) * ' '\n",
    "\n",
    "    comment_string = comment_string.lower().translate(str.maketrans(chars_to_replace, whitespace_to_replace_with))\n",
    "    return comment_string\n",
    "\n",
    "def acceptable_token(token):\n",
    "    \"\"\" Return True if token is longer than one character and is not present in ENGLISH_STOPWORDS\n",
    "    \"\"\"\n",
    "    return (len(token) > 1 and token not in ENGLISH_STOPWORDS)\n",
    "\n",
    "def tokenize(giant_comment_string):\n",
    "    \"\"\" Return list of word tokens from given string.\n",
    "    \"\"\"\n",
    "    tokens = giant_comment_string.split(' ')\n",
    "    return list(filter(acceptable_token, tokens))\n",
    "\n",
    "def create_counter_object(giant_comment_string):\n",
    "    \"\"\" Return Counter with word counters for given string.\n",
    "    \"\"\"\n",
    "    word_counter = Counter(tokenize(giant_comment_string))\n",
    "    return word_counter\n",
    "\n",
    "def top_adjectives(giant_comment_string, num_of_words=10):\n",
    "    \"\"\" Return list with most common adjectives in given string.\n",
    "    \"\"\"\n",
    "\n",
    "    def find_adjectives(list_of_word_pos_tuple):\n",
    "        return list_of_word_pos_tuple[1] == 'JJ'\n",
    "\n",
    "    comment_words_POS = nltk.pos_tag(tokenize(giant_comment_string))\n",
    "    comment_adj_counter = Counter([adj[0] for adj in list(filter(find_adjectives, comment_words_POS))])\n",
    "    return comment_adj_counter.most_common(num_of_words)\n",
    "\n",
    "# TODO: Determine association metric to use\n",
    "# http://www.nltk.org/_modules/nltk/metrics/association.html\n",
    "def top_ngrams(giant_comment_string, num_of_words=15, ngram=2):\n",
    "    \"\"\" Return list with most frequently appearing n-grams in given string.\n",
    "    \"\"\"\n",
    "\n",
    "    if ngram == 2:\n",
    "        finder = BigramCollocationFinder.from_words(tokenize(giant_comment_string))\n",
    "        return finder.nbest(bigram_measures.likelihood_ratio, num_of_words)\n",
    "    elif ngram == 3:\n",
    "        finder = TrigramCollocationFinder.from_words(tokenize(giant_comment_string))\n",
    "        return finder.nbest(trigram_measures.likelihood_ratio, num_of_words)\n",
    "    else:\n",
    "        return \"Error: Only bi- and trigrams supported.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Move analysis helper function into their own py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_giant_comment_string = giant_cleaned_string(data_df_subset[data_df_subset['male']]['comments'])\n",
    "female_giant_comment_string = giant_cleaned_string(data_df_subset[data_df_subset['female']]['comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_word_counter = create_counter_object(female_giant_comment_string)\n",
    "male_word_counter = create_counter_object(male_giant_comment_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "37134"
     },
     "metadata": {},
     "execution_count": 165
    }
   ],
   "source": [
    "sum(female_word_counter.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "10120"
     },
     "metadata": {},
     "execution_count": 166
    }
   ],
   "source": [
    "sum(male_word_counter.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Log-Odds Ratio of Words\n",
    "# len(male_giant_comment_string.split(' ')) # 6718 \n",
    "# len(female_giant_comment_string.split(' ')) # 14882"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "male_top_50 = male_word_counter.most_common(50)\n",
    "female_top_50 = female_word_counter.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[('like', 96), ('think', 84), ('see', 54), ('would', 53), (\"i'm\", 53), ('back', 52), ('really', 51), ('get', 49), ('fans', 48), ('year', 47), ('even', 47), (\"'s\", 45), (\"'i\", 45), ('one', 44), ('still', 42), ('know', 40), ('much', 40), ('bts', 39), ('go', 37), ('heechul', 37), ('also', 35), ('sm', 35), ('big', 35), ('yg', 35), ('since', 33), ('i‚Äôm', 33), ('hope', 33), ('people', 33), ('time', 32), ('gt', 32), ('reporter', 31), ('right', 30), ('comments', 29), ('going', 28), ('way', 28), ('say', 28), ('group', 28), ('good', 27), ('hate', 27), ('well', 26), ('bighit', 26), ('sure', 25), ('love', 24), ('could', 24), ('debut', 24), ('got', 23), ('though', 23), (\"can't\", 23), ('lot', 23), ('it‚Äôs', 23)]\n\n[('like', 460), ('really', 238), (\"i'm\", 221), ('song', 206), ('think', 203), ('even', 193), ('one', 187), ('also', 175), ('group', 173), ('would', 165), ('see', 165), ('people', 156), ('know', 152), (\"'i\", 148), ('love', 146), ('good', 144), ('album', 141), ('music', 135), ('much', 132), ('get', 128), ('first', 120), ('well', 115), ('time', 115), ('songs', 107), ('still', 107), (\"'t\", 99), (\"'s\", 99), ('since', 98), ('year', 97), ('make', 94), ('comeback', 91), ('lot', 91), ('kpop', 89), ('groups', 89), ('lol', 87), ('amp', 86), ('going', 84), ('show', 84), ('something', 83), ('looks', 82), ('way', 82), ('gt', 82), ('feel', 81), ('ni', 81), ('could', 79), ('hope', 79), ('girl', 78), ('say', 77), ('debut', 77), ('korean', 76)]\n"
    }
   ],
   "source": [
    "print(male_top_50)\n",
    "print()\n",
    "print(female_top_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_male_words = set(male_word_counter.keys()) - set(female_word_counter.keys())\n",
    "unique_female_words = set(female_word_counter.keys()) - set(male_word_counter.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_male_word_counter = Counter()\n",
    "unique_female_word_counter = Counter()\n",
    "\n",
    "for word in unique_male_words:\n",
    "    unique_male_word_counter[word] = male_word_counter[word] \n",
    "\n",
    "for word in unique_female_words:\n",
    "    unique_female_word_counter[word] = female_word_counter[word] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_male_words_str = ' '.join(unique_male_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_male_words_str = ' '.join(unique_male_words)\n",
    "unique_female_words_str = ' '.join(unique_female_words)\n",
    "unique_male_adj_tuples = list(filter(lambda x: x[1]=='JJ', nltk.pos_tag(tokenize(unique_male_words_str)))) # filter for words uniquely used toward male groups/people AND are adjectives\n",
    "unique_female_adj_tuples = list(filter(lambda x: x[1]=='JJ', nltk.pos_tag(tokenize(unique_female_words_str)))) # filter for words uniquely used toward male groups/people AND are adjectives\n",
    "unique_male_adj = [tup[0] for tup in unique_male_adj_tuples]\n",
    "unique_female_adj = [tup[0] for tup in unique_female_adj_tuples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_male_adj_counter = Counter()\n",
    "unique_female_adj_counter = Counter()\n",
    "\n",
    "for word in unique_male_adj:\n",
    "    unique_male_adj_counter[word] = male_word_counter[word] \n",
    "\n",
    "for word in unique_female_adj:\n",
    "    unique_female_adj_counter[word] = female_word_counter[word] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[('enlist', 12), ('enlistment', 10), ('wonho', 9), ('mx', 8), ('sergeant', 7), ('interpretation', 7), ('onew', 6), ('ygtb', 5), ('hara', 4), ('bh', 4), ('goo', 4), (\"'welcome\", 4), ('it‚Äôll', 3), ('rejoin', 3), ('important', 3), ('boo', 3), ('spanish', 3), ('defamatory', 3), ('misogyny', 3), ('summary', 3), ('ambitious', 2), (\"year'\", 2), ('learned', 2), ('sparked', 2), ('rid', 2), ('fanname', 2), ('smthg', 2), ('cleared', 2), ('wig', 2), ('njonghyun', 2), ('ntreasure', 2), ('njongdae', 2), ('jumbo', 2), ('tribute', 2), ('netz', 2), ('corporate', 2), ('bt21', 2), ('üòÅüòÅ', 2), ('pearl', 2), ('you‚Äôll', 2), ('applied', 2), ('website', 2), ('considerable', 2), ('feb', 2), ('poet', 2), ('grateful', 2), ('literal', 2), ('innovative', 2), ('subsidary', 2), ('intern', 1), ('nwhich', 1), ('cancel', 1), ('sangbyeong', 1), ('uniform', 1), ('wolo', 1), ('intellectual', 1), ('sangdeungbyeong', 1), ('tsol', 1), ('dissimilar', 1), ('seventeen‚Äôs', 1), ('reasonable', 1), ('ÏÇ¨ÎûåÎì§Ïù¥', 1), (\"'ouch\", 1), ('krystal', 1), (\"worse'\", 1), ('nate', 1), ('Ïó¨ÏûêÎì§ÏùÄ', 1), ('ai', 1), ('miserable', 1), ('shafted', 1), (\"'settle\", 1), ('asthma', 1), ('overblown', 1), ('niblings', 1), ('craaaaazy', 1), ('frame', 1), ('clarified', 1), ('graduated', 1), ('yeonjung', 1), ('ideungbyeong', 1), ('impossible', 1), ('honor', 1), (\"hah'\", 1), ('vibed', 1), (\"sexy'\", 1), ('spree', 1), ('tirtir', 1), ('interactive', 1), ('loveshot', 1), (\"leader'\", 1), (\"baaaaack'\", 1), ('bossy', 1), ('political', 1), ('gose', 1), ('contradict', 1), ('collabed', 1), ('kfanbase', 1), ('interpreted', 1), ('nps', 1), ('ouch', 1)]\n"
    }
   ],
   "source": [
    "print(unique_male_adj_counter.most_common(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[('seulgi', 37), ('arin', 30), ('fun', 25), ('purple', 21), ('strong', 18), ('western', 17), ('mvs', 16), ('cube', 14), ('black', 14), ('visual', 14), ('adorable', 13), ('genre', 13), ('standard', 12), ('ssak3', 12), ('ot5', 12), ('psycho', 12), ('sns', 11), ('simple', 11), ('cannot', 11), ('solar', 11), ('cb', 10), ('mad', 10), ('ridiculous', 10), ('incredible', 10), ('natural', 10), ('instrumental', 9), ('ioi', 9), ('uncover', 9), ('aware', 9), ('common', 9), ('goeun', 9), ('average', 9), ('nonstop', 9), ('shot', 9), ('abc', 8), ('gothic', 8), ('front', 8), ('clear', 8), ('teen', 8), ('excellent', 7), (\"yukika's\", 7), ('cut', 7), ('involved', 7), (\"now'\", 7), ('pick', 7), ('skip', 7), ('shade', 7), ('mixed', 7), ('minimum', 6), ('healthy', 6), ('white', 6), ('idle', 6), ('hostess', 6), ('valid', 6), ('prostitute', 6), ('‚Äòmusic', 6), ('iz', 6), ('confirmed', 6), ('attractive', 6), ('colour', 6), ('unfortunate', 6), ('minute', 6), ('taboo', 6), ('cha', 6), ('double', 6), ('typical', 6), ('ig', 5), ('medical', 5), ('candy', 5), ('correct', 5), ('featured', 5), ('uk', 5), ('rich', 5), ('underrated', 5), ('solid', 5), ('asian', 5), ('app', 5), ('angry', 5), ('jealous', 5), ('nshe', 5), (\"ya'll\", 5), ('everglow', 5), ('toxic', 5), ('theory', 5), ('extent', 5), ('abt', 5), ('fnc', 5), ('seulrene', 5), ('intentional', 4), ('nit', 4), ('smngg', 4), ('appear', 4), ('length', 4), ('traditional', 4), ('hey', 4), ('soobin‚Äôs', 4), ('tbl', 4), ('blew', 4), ('cultural', 4), ('fantastic', 4)]\n"
    }
   ],
   "source": [
    "print(unique_female_adj_counter.most_common(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What adjectives are used? Verbs? \n",
    "\n",
    "[Categorizing and Tagging Words](https://www.nltk.org/book/ch05.html)\n",
    "\n",
    "[collocations](https://www.nltk.org/howto/collocations.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most common ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.collocations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('red', 'velvet', 'irene'),\n ('red', 'velvet', 'quality'),\n ('experimental', 'red', 'velvet'),\n ('lacks', 'red', 'velvet'),\n ('red', 'velvet', 'dying'),\n ('red', 'velvet', 'photobooks'),\n ('red', 'velvet', 'pushes'),\n ('red', 'velvet', 'red'),\n ('velvet', 'red', 'velvet'),\n ('die', 'red', 'velvet'),\n ('nmaybe', 'red', 'velvet'),\n ('red', 'velvet', 'charm'),\n ('red', 'velvet', 'nmaybe'),\n ('yeri', 'red', 'velvet'),\n ('amp', 'red', 'velvet'),\n ('red', 'velvet', 'favorites'),\n ('respect', 'red', 'velvet'),\n ('created', 'red', 'velvet'),\n ('typical', 'red', 'velvet'),\n ('friends', 'red', 'velvet'),\n ('red', 'velvet', 'showing'),\n ('wrote', 'red', 'velvet'),\n ('red', 'velvet', 'car'),\n ('compare', 'red', 'velvet'),\n ('reputation', 'red', 'velvet'),\n ('red', 'velvet', 'lost'),\n ('love', 'red', 'velvet'),\n ('beat', 'red', 'velvet'),\n ('red', 'velvet', 'beat'),\n ('red', 'velvet', 'group'),\n ('follow', 'red', 'velvet'),\n ('red', 'velvet', 'also'),\n ('special', 'red', 'velvet'),\n ('gg', 'red', 'velvet'),\n ('part', 'red', 'velvet'),\n ('red', 'velvet', 'high'),\n ('red', 'velvet', 'making'),\n ('twice', 'red', 'velvet'),\n ('albums', 'red', 'velvet'),\n ('red', 'velvet', 'honestly'),\n ('red', 'velvet', 'done'),\n ('blackpink', 'red', 'velvet'),\n ('red', 'velvet', 'blackpink'),\n ('red', 'velvet', 'seulgi'),\n ('red', 'velvet', 'released'),\n ('members', 'red', 'velvet'),\n ('mamamoo', 'red', 'velvet'),\n ('red', 'velvet', \"i've\"),\n ('thought', 'red', 'velvet'),\n ('red', 'velvet', 'big')]"
     },
     "metadata": {},
     "execution_count": 178
    }
   ],
   "source": [
    "top_ngrams(female_giant_comment_string, num_of_words=50, ngram=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('defending', 'stray', 'kids'),\n ('discussion', 'stray', 'kids'),\n ('familiar', 'stray', 'kids'),\n ('perception', 'stray', 'kids'),\n ('stray', 'kids', 'crackhead'),\n ('stray', 'kids', 'draws'),\n ('stray', 'kids', 'objectively'),\n ('stray', 'kids', 'touring'),\n ('stray', 'kids', 'specifically'),\n ('opinion', 'stray', 'kids'),\n ('stray', 'kids', 'called'),\n ('stray', 'kids', 'marketed'),\n ('blm', 'stray', 'kids'),\n ('point', 'stray', 'kids'),\n ('stray', 'kids', 'group'),\n ('groups', 'stray', 'kids'),\n ('love', 'stray', 'kids'),\n ('stray', 'kids', 'would'),\n ('culture', 'stray', 'kids'),\n ('stray', 'kids', \"i'm\"),\n ('hip', 'hop', 'rap'),\n ('features', 'hip', 'hop'),\n ('hoping', 'hip', 'hop'),\n ('consider', 'hip', 'hop'),\n ('hip', 'hop', 'banger'),\n ('american', 'hip', 'hop'),\n ('hip', 'hop', 'pop'),\n ('also', 'hip', 'hop'),\n ('find', 'new', 'home'),\n ('pretty', 'much', 'contained'),\n ('almost', 'pretty', 'much'),\n ('bans', 'depending', 'severity'),\n ('concert', 'entails', 'proper'),\n ('entails', 'proper', 'guidelines'),\n ('permanent', 'bans', 'depending'),\n ('temporary', 'permanent', 'bans'),\n ('also', 'discussed', 'posibble'),\n ('guidelines', 'also', 'discussed'),\n ('present', 'also', 'discussed'),\n ('guys', 'really', 'insensitive'),\n ('exo', 'sc', 'possibe'),\n ('opposite', 'exo', 'sc'),\n ('teamin', 'exo', 'sc'),\n ('heavily', 'black', 'culture'),\n ('depending', 'severity', 'actions'),\n ('hurl', 'meaningless', 'insults'),\n ('launch', 'search', 'party'),\n ('lived', 'western', 'countries'),\n ('please', 'continue', 'showing'),\n ('action', 'temporary', 'permanent')]"
     },
     "metadata": {},
     "execution_count": 338
    }
   ],
   "source": [
    "top_ngrams(male_giant_comment_string, num_of_words=50, ngram=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most common adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('good', 140),\n ('much', 94),\n ('korean', 73),\n ('first', 69),\n ('sure', 68),\n ('many', 66),\n ('new', 66),\n ('great', 64),\n ('different', 63),\n (\"i'm\", 62),\n ('big', 58),\n ('last', 48),\n ('red', 46),\n ('next', 40),\n ('right', 39),\n ('single', 39),\n ('full', 35),\n ('whole', 35),\n ('main', 35),\n ('top', 34),\n ('bad', 33),\n ('ni', 33),\n ('happy', 32),\n ('japanese', 32),\n ('little', 31),\n ('digital', 31),\n ('similar', 30),\n ('song', 30),\n ('nice', 29),\n ('live', 29),\n ('real', 28),\n ('public', 28),\n ('mean', 27),\n ('english', 26),\n ('high', 26),\n ('it‚Äôs', 26),\n ('female', 25),\n ('wrong', 24),\n ('favorite', 24),\n (\"can't\", 23),\n ('sm', 23),\n ('able', 23),\n ('album', 22),\n ('irene', 22),\n ('popular', 22),\n (\"they're\", 21),\n ('lol', 21),\n ('beautiful', 21),\n ('huge', 20),\n ('general', 20)]"
     },
     "metadata": {},
     "execution_count": 185
    }
   ],
   "source": [
    "top_adjectives(female_giant_comment_string, num_of_words=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('big', 35),\n ('much', 28),\n ('good', 27),\n ('sure', 24),\n ('many', 22),\n ('vlive', 19),\n ('korean', 18),\n (\"i'm\", 18),\n ('english', 17),\n ('happy', 17),\n ('last', 17),\n ('right', 14),\n ('sm', 13),\n ('huge', 13),\n ('i‚Äôm', 13),\n ('popular', 12),\n ('malicious', 12),\n ('new', 11),\n ('ready', 11),\n ('first', 11),\n ('different', 11),\n ('public', 11),\n ('full', 10),\n ('recent', 9),\n ('little', 9),\n ('ni', 9),\n ('whole', 9),\n ('it‚Äôs', 9),\n ('bad', 9),\n ('possible', 9),\n ('military', 9),\n ('able', 9),\n ('live', 9),\n ('yg', 9),\n ('online', 8),\n ('due', 8),\n ('gt', 8),\n ('next', 8),\n ('nct', 7),\n ('great', 7),\n ('song', 7),\n ('lol', 7),\n ('sad', 7),\n ('actual', 7),\n ('male', 7),\n ('single', 7),\n ('mean', 7),\n ('long', 7),\n (\"can't\", 7),\n ('curious', 7)]"
     },
     "metadata": {},
     "execution_count": 184
    }
   ],
   "source": [
    "top_adjectives(male_giant_comment_string, num_of_words=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596260209997",
   "display_name": "Python 3.8.3 64-bit ('gendered-discussion': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}