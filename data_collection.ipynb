{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Gather more data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planning / Scratch Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do /r/kpop commenters talk differently about male vs. female groups?\n",
    "\n",
    "Initial exploration of this question:\n",
    "- Identify submissions on 2 all-male groups, 2 all-female groups\n",
    "- Collect their comments\n",
    "- Contrast comments in general to \"typical\" reddit language (using /r/funny as a standard)\n",
    "- Contrast comments on male group vs female group "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Pushshift to get reddit comments\n",
    "\n",
    "See [Pushshift's GitHub API README](https://github.com/pushshift/api)\n",
    "\n",
    "> Search for the most recent comments mentioning the word \"science\" within the subreddit /r/askscience\n",
    ">\n",
    "> `https://api.pushshift.io/reddit/search/comment/?q=science&subreddit=askscience`\n",
    "\n",
    "Retrieve all comment ids for a submission object\n",
    "\n",
    "`https://api.pushshift.io/reddit/submission/comment_ids/{base36_submission_id}`\n",
    "\n",
    "[New to Pushshift FAQ](https://www.reddit.com/r/pushshift/comments/bcxguf/new_to_pushshift_read_this_faq/)\n",
    "\n",
    "[Pushshift Reddit API v4.0 Documentation](https://reddit-api.readthedocs.io/en/latest/#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not-comprehensive related works:\n",
    "- \"A Community of Curious Souls: An Analysis of Commenting Behavior on TED Talks Videos\" (Tsou, Thelwall, Mongeon, and Sugimoto, 2014)\n",
    "- \"YouTube science channel video presenters and comments: female friendly or vestiges of sexism?\" (Thelwall and Mas-Bleda, 2018)\n",
    "- \"Shirtless and dangerous: Quantifying linguistic signals of gender bias in an online fiction writing community.\" (Fast, Vachovsky, and Bernstein, 2016)\n",
    "- \"Using language models to quantify gender bias in sports journalism\" (Fu, Danescu-Niculescu-Mizil, Lee, 2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "ENGLISH_STOPWORDS = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect relevant /r/kpop submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = 'https://api.pushshift.io/reddit/search/submission/?subreddit=kpop&score=>50&num_comments=>50&size=100' # TODO: Collect more than 100 posts\n",
    "response = requests.get(url)\n",
    "post_titles = [post['title'] for post in response.json()['data']]\n",
    "post_ids = [post['id'] for post in response.json()['data']]\n",
    "post_id = post_ids[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the values that we can access for each submission?\n",
    "\n",
    "```\n",
    "response.json()['data'][1].keys()\n",
    "\n",
    "dict_keys(['all_awardings', 'allow_live_comments', 'author', 'author_flair_css_class', 'author_flair_richtext', 'author_flair_template_id', 'author_flair_text', \n",
    "'author_flair_text_color', 'author_flair_type', 'author_fullname', 'author_patreon_flair', 'author_premium', 'awarders', 'can_mod_post', 'contest_mode', 'created_utc', 'domain',\n",
    "'full_link', 'gildings', 'id', 'is_crosspostable', 'is_meta', 'is_original_content', 'is_reddit_media_domain', 'is_robot_indexable', 'is_self', 'is_video',\n",
    "'link_flair_background_color', 'link_flair_css_class', 'link_flair_richtext', 'link_flair_template_id', 'link_flair_text', 'link_flair_text_color', 'link_flair_type', 'locked',\n",
    "'media_only', 'no_follow', 'num_comments', 'num_crossposts', 'over_18', 'parent_whitelist_status', 'permalink', 'pinned', 'pwls', 'retrieved_on', 'score', 'selftext',\n",
    "'send_replies', 'spoiler', 'stickied', 'subreddit', 'subreddit_id', 'subreddit_subscribers', 'subreddit_type', 'thumbnail', 'title', 'total_awards_received', 'treatment_tags',\n",
    "'upvote_ratio', 'url', 'url_overridden_by_dest', 'whitelist_status', 'wls'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect comments given post_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = 'https://api.pushshift.io/reddit/comment/search?link_id=' + post_id\n",
    "response = requests.get(url, headers={'User-Agent': user_agent})\n",
    "comments_json = response.json()['data']\n",
    "comment_bodies = [comment['body'] for comment in comments_json]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the values that we can access for each comment?\n",
    "\n",
    "```python\n",
    "comments_json[0].keys()\n",
    "\n",
    "dict_keys(['all_awardings', 'approved_at_utc', 'associated_award', 'author', 'author_flair_background_color', 'author_flair_css_class', 'author_flair_richtext',\n",
    "'author_flair_template_id', 'author_flair_text', 'author_flair_text_color', 'author_flair_type', 'author_fullname', 'author_patreon_flair', 'author_premium', 'awarders',\n",
    "'banned_at_utc', 'body', 'can_mod_post', 'collapsed', 'collapsed_because_crowd_control', 'collapsed_reason', 'created_utc', 'distinguished', 'edited', 'gildings', 'id', \n",
    "'is_submitter', 'link_id', 'locked', 'no_follow', 'parent_id', 'permalink', 'retrieved_on', 'score', 'send_replies', 'stickied', 'subreddit', 'subreddit_id', 'top_awarded_type', \n",
    "'total_awards_received', 'treatment_tags'])\n",
    "   \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for i, post_id in enumerate(post_ids):\n",
    "    url = 'https://api.pushshift.io/reddit/comment/search?link_id=' + post_id # TODO: Collect more than 25 comments per post\n",
    "    response = requests.get(url, headers={'User-Agent': user_agent})\n",
    "    comments_json = response.json()['data']\n",
    "    comment_bodies = [comment['body'] for comment in comments_json]\n",
    "    entry = [post_id, post_titles[i], comment_bodies]\n",
    "    data.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame(data, columns=['id', 'title', 'comments'])\n",
    "data_df.to_csv('rkpop-data.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading from saved CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('rkpop-data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify male vs female groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "m_f_mapping = {'male': {'EXO', 'NCT', 'BTS', 'Stray Kids', 'G-Dragon', 'Big Bang', \n",
    "                        'AB6IX', 'Golden Child', 'SEVENTEEN', 'Top Secret', 'TST', \n",
    "                        'ONEUS', 'TVXQ', 'PENTAGON', 'THE BOYZ', 'VERIVERY', 'Ravi', 'WayV', 'VIXX'},\n",
    "               'female': {'GFriend', \"Girl's Day\", 'Red Velvet', 'AOA', 'BLACKPINK', \n",
    "               'Momoland', 'miss A', 'MAMAMOO', 'ITZY', 'Sunmi', 'Weeekly', 'NiziU', \n",
    "               'NATTY', 'Twice', 'LOONA', 'After School', 'IU', 'IZ*ONE', 'WJSN', \n",
    "               'Cosmic Girls', 'DIA', 'CHUNGHA'}\n",
    "}\n",
    "m_f_mapping['male'] = {g.lower() for g in m_f_mapping['male']}\n",
    "m_f_mapping['female'] = {g.lower() for g in m_f_mapping['female']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tag submissions with male or female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Count a submission as 'male' or 'female' only if it has one gender present?\n",
    "data_df['male'] = data_df.title.apply(lambda t: any(group in t.lower() for group in m_f_mapping['male']))\n",
    "data_df['female'] = data_df.title.apply(lambda t: any(group in t.lower() for group in m_f_mapping['female']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        id                                              title  \\\n27  hegnwo  TWICE, IZ*ONE, (G)I-DLE, SEVENTEEN, NCT 127, T...   \n\n                                             comments  male  female  \n27  ['Seventeen and Izone collab stage to consolid...  True    True  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>comments</th>\n      <th>male</th>\n      <th>female</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>27</th>\n      <td>hegnwo</td>\n      <td>TWICE, IZ*ONE, (G)I-DLE, SEVENTEEN, NCT 127, T...</td>\n      <td>['Seventeen and Izone collab stage to consolid...</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# Checking if any overlapping...\n",
    "data_df[data_df['male'] & data_df['female']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remove overlapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean comment text and prepare for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[How to strip punctuation from a string](https://stackoverflow.com/questions/265960/best-way-to-strip-punctuation-from-a-string)\n",
    "\n",
    "`s.translate(str.maketrans('', '', string.punctuation))`\n",
    "\n",
    "[`maketrans` documentation](https://docs.python.org/3.3/library/stdtypes.html?highlight=maketrans#str.maketrans)\n",
    "\n",
    "[Removing URLs from a string](https://stackoverflow.com/questions/11331982/how-to-remove-any-url-within-a-string-in-python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def giant_cleaned_string(series_of_list_of_comments):\n",
    "    \"\"\"Return string from Pandas Series of lists of strings.\n",
    "    \n",
    "    Combines multiple pandas rows with lists of strings into one giant string with URLs and punctuation removed.\n",
    "    \"\"\"\n",
    "    comment_string = ' '.join(series_of_list_of_comments.apply(lambda x: ' '.join(x.split())))\n",
    "    comment_string = re.sub('http://\\S+|https://\\S+', '', comment_string)\n",
    "\n",
    "    chars_to_replace = string.punctuation[:6]+string.punctuation[7:]+'“”\\n' # Don't remove single quotation mark\n",
    "    whitespace_to_replace_with = len(chars_to_replace) * ' '\n",
    "\n",
    "    comment_string = comment_string.lower().translate(str.maketrans(chars_to_replace, whitespace_to_replace_with))\n",
    "    return comment_string\n",
    "\n",
    "def acceptable_token(token):\n",
    "    \"\"\" Return True if token is longer than one character and is not present in ENGLISH_STOPWORDS\n",
    "    \"\"\"\n",
    "    return (len(token) > 1 and token not in ENGLISH_STOPWORDS)\n",
    "\n",
    "def tokenize(giant_comment_string):\n",
    "    \"\"\" Return list of word tokens from given string.\n",
    "    \"\"\"\n",
    "    tokens = giant_comment_string.split(' ')\n",
    "    return list(filter(acceptable_token, tokens))\n",
    "\n",
    "def create_counter_object(giant_comment_string):\n",
    "    \"\"\" Return Counter with word counters for given string.\n",
    "    \"\"\"\n",
    "    word_counter = Counter(tokenize(giant_comment_string))\n",
    "    return word_counter\n",
    "\n",
    "def top_adjectives(giant_comment_string, num_of_words=10):\n",
    "    \"\"\" Return list with most common adjectives in given string.\n",
    "    \"\"\"\n",
    "\n",
    "    def find_adjectives(list_of_word_pos_tuple):\n",
    "        return list_of_word_pos_tuple[1] == 'JJ'\n",
    "\n",
    "    comment_words_POS = nltk.pos_tag(tokenize(giant_comment_string))\n",
    "    comment_adj_counter = Counter([adj[0] for adj in list(filter(find_adjectives, comment_words_POS))])\n",
    "    return comment_adj_counter.most_common(num_of_words)\n",
    "\n",
    "# TODO: Determine association metric to use\n",
    "# http://www.nltk.org/_modules/nltk/metrics/association.html\n",
    "def top_ngrams(giant_comment_string, num_of_words=15, ngram=2):\n",
    "    \"\"\" Return list with most frequently appearing n-grams in given string.\n",
    "    \"\"\"\n",
    "\n",
    "    if ngram == 2:\n",
    "        finder = BigramCollocationFinder.from_words(tokenize(giant_comment_string))\n",
    "        return finder.nbest(bigram_measures.likelihood_ratio, num_of_words)\n",
    "    elif ngram == 3:\n",
    "        finder = TrigramCollocationFinder.from_words(tokenize(giant_comment_string))\n",
    "        return finder.nbest(trigram_measures.likelihood_ratio, num_of_words)\n",
    "    else:\n",
    "        return \"Error: Only bi- and trigrams supported.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_giant_comment_string = giant_cleaned_string(data_df[data_df['male']]['comments'])\n",
    "female_giant_comment_string = giant_cleaned_string(data_df[data_df['female']]['comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_word_counter = create_counter_object(female_giant_comment_string)\n",
    "male_word_counter = create_counter_object(male_giant_comment_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "23918"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "sum(female_word_counter.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "13298"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "sum(male_word_counter.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Log-Odds Ratio of Words\n",
    "# len(male_giant_comment_string.split(' ')) # 6718 \n",
    "# len(female_giant_comment_string.split(' ')) # 14882"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "male_top_50 = male_word_counter.most_common(50)\n",
    "female_top_50 = female_word_counter.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[('like', 157), ('really', 98), ('one', 84), ('song', 76), ('people', 74), (\"i'm\", 73), ('think', 71), ('would', 68), ('love', 66), ('time', 65), ('much', 58), ('get', 56), ('even', 56), ('know', 52), ('see', 49), ('also', 49), (\"'i\", 49), ('kpop', 48), ('songs', 47), ('good', 46), ('still', 46), ('album', 46), ('group', 46), ('fans', 45), ('well', 42), ('first', 42), ('groups', 42), ('going', 36), ('years', 36), ('since', 36), ('lot', 36), ('go', 35), ('gt', 34), ('new', 34), ('culture', 34), ('actually', 33), ('way', 32), ('ni', 32), ('music', 32), ('make', 32), ('could', 31), ('back', 31), ('bts', 31), ('sm', 31), (\"that's\", 30), ('pretty', 30), ('feel', 29), ('never', 28), ('sure', 28), ('though', 28)]\n\n[('like', 295), ('really', 185), ('one', 135), ('song', 130), ('think', 127), ('even', 122), (\"'i\", 121), (\"i'm\", 117), ('people', 112), ('still', 110), ('also', 108), ('kpop', 105), ('group', 104), ('know', 100), ('good', 97), ('would', 94), ('songs', 93), ('much', 91), ('see', 88), ('well', 88), ('get', 86), ('twice', 83), (\"'s\", 81), ('time', 80), ('music', 78), ('groups', 77), ('go', 63), ('love', 63), ('something', 63), ('pop', 62), ('since', 61), ('make', 61), ('album', 60), ('comeback', 60), ('got', 60), ('members', 60), ('though', 56), ('it’s', 55), ('could', 54), ('lot', 54), ('say', 54), ('want', 53), ('way', 52), ('going', 52), ('right', 52), ('girl', 51), ('better', 50), ('back', 50), ('debut', 50), ('look', 49)]\n"
    }
   ],
   "source": [
    "print(male_top_50)\n",
    "print()\n",
    "print(female_top_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_male_words = set(male_word_counter.keys()) - set(female_word_counter.keys())\n",
    "unique_female_words = set(female_word_counter.keys()) - set(male_word_counter.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_male_word_counter = Counter()\n",
    "unique_female_word_counter = Counter()\n",
    "\n",
    "for word in unique_male_words:\n",
    "    unique_male_word_counter[word] = male_word_counter[word] \n",
    "\n",
    "for word in unique_female_words:\n",
    "    unique_female_word_counter[word] = female_word_counter[word] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_male_words_str = ' '.join(unique_male_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_male_words_str = ' '.join(unique_male_words)\n",
    "unique_female_words_str = ' '.join(unique_female_words)\n",
    "unique_male_adj_tuples = list(filter(lambda x: x[1]=='JJ', nltk.pos_tag(tokenize(unique_male_words_str)))) # filter for words uniquely used toward male groups/people AND are adjectives\n",
    "unique_female_adj_tuples = list(filter(lambda x: x[1]=='JJ', nltk.pos_tag(tokenize(unique_female_words_str)))) # filter for words uniquely used toward male groups/people AND are adjectives\n",
    "unique_male_adj = [tup[0] for tup in unique_male_adj_tuples]\n",
    "unique_female_adj = [tup[0] for tup in unique_female_adj_tuples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_male_adj_counter = Counter()\n",
    "unique_female_adj_counter = Counter()\n",
    "\n",
    "for word in unique_male_adj:\n",
    "    unique_male_adj_counter[word] = male_word_counter[word] \n",
    "\n",
    "for word in unique_female_adj:\n",
    "    unique_female_adj_counter[word] = female_word_counter[word] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[('rtk', 12), ('vixx', 11), ('golcha', 7), ('superm', 6), ('sc', 6), (\"here's\", 6), ('dog', 6), ('yohan', 5), ('discussed', 4), ('unbreakable', 4), ('nhappy', 4), ('animal', 3), ('double', 3), ('handsome', 3), ('unusual', 3), ('nokay', 3), ('busy', 3), ('excellent', 3), ('y’all', 3), ('skz', 3), ('youthful', 3), ('profile', 3), ('raw', 3), ('pet', 3), ('tempo', 3), ('corden', 3), ('electric', 3), ('normalize', 3), ('monotree', 3), ('ode', 3), ('grand', 3), ('people’s', 3), ('equal', 3), ('website', 3), ('tst', 3), ('jaejoong', 3), ('obv', 2), ('umpah', 2), ('subject', 2), ('superhuman', 2), ('sixth', 2), ('cpop', 2), ('subs', 2), ('army’s', 2), ('narrative', 2), ('jellyfish', 2), ('national', 2), ('temporary', 2), ('irresponsible', 2), ('jazzy', 2), ('manipulative', 2), ('leadt', 2), ('opposite', 2), ('adventure', 2), ('criticised', 2), ('sentimental', 2), ('formal', 2), ('piece', 2), ('armys', 2), ('visible', 2), ('john', 2), (\"else's\", 2), ('tricky', 2), ('amazed', 2), ('mymy', 2), ('unpaid', 2), ('funeral', 2), ('logical', 2), ('dive', 2), ('aju', 2), ('ballady', 2), ('unfair', 2), ('infinite', 2), ('posibble', 2), ('solar', 2), (\"'been\", 2), ('compass', 2), ('meaningless', 2), ('nsome', 2), ('username', 2), ('finish', 2), ('upcoming', 2), ('laptop', 2), ('traditional', 2), ('mgt', 1), ('nelectric', 1), ('nimo', 1), ('ninterlude', 1), ('unreasonable', 1), ('sometime', 1), ('eccentric', 1), ('smooth', 1), ('squishy', 1), ('feasible', 1), ('lash', 1), (\"mblaq's\", 1), (\"'younghoona\", 1), ('funkteen', 1), (\"feels'\", 1), ('inspirational', 1)]\n"
    }
   ],
   "source": [
    "print(unique_male_adj_counter.most_common(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[('mld', 13), ('lisa', 11), ('tzuyu', 11), ('fancams', 9), ('choa', 9), ('teddy', 9), ('nayeon', 8), ('female', 8), ('fancy', 8), (\"girl's\", 7), ('comfortable', 6), ('innocent', 6), ('ridiculous', 6), ('hot', 6), ('forgot', 6), ('write', 6), (\"girls'\", 6), ('sixteen', 6), ('aoa', 5), ('correct', 5), ('photo', 5), ('wtf', 5), ('mental', 5), ('powerful', 5), ('vita', 5), ('whistle', 5), ('vlive', 5), ('ktl', 4), ('sian', 4), ('jimin’s', 4), ('broad', 4), ('local', 4), ('technical', 4), ('unpopular', 4), ('impressive', 4), ('extra', 4), ('mediocre', 4), ('screentime', 4), ('sakura', 4), ('react', 4), ('iggy', 4), ('accustomed', 4), ('lied', 4), ('dead', 4), ('latin', 4), (\"pretty'\", 4), ('liberal', 4), ('nana', 4), ('dan', 4), ('fei', 4), ('lightstick', 4), ('npeople', 4), ('baam', 4), ('various', 4), ('childish', 4), ('valid', 3), ('usual', 3), ('mine', 3), ('nayun', 3), ('political', 3), ('awful', 3), ('precious', 3), ('photocard', 3), ('sucked', 3), ('translate', 3), ('unlikely', 3), (\"😍'\", 3), ('sunday', 3), ('typical', 3), ('achievement', 3), ('understandable', 3), ('competitive', 3), ('pose', 3), (\"song'\", 3), (\"group's\", 3), ('controlled', 3), ('teen', 3), ('moral', 3), ('upset', 3), ('legendary', 3), ('smart', 3), ('everyday', 3), ('mako', 3), ('ara', 3), ('defensive', 3), ('harsh', 3), ('pandemic', 3), ('silent', 3), (\"loona'\", 3), (\"velvet's\", 3), ('alt', 3), ('nis', 3), ('natural', 3), ('nidk', 3), ('hitomi', 2), ('maría', 2), ('weak', 2), ('lookin', 2), ('taiwanese', 2), ('breakdown', 2)]\n"
    }
   ],
   "source": [
    "print(unique_female_adj_counter.most_common(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What adjectives are used? Verbs? \n",
    "\n",
    "[Categorizing and Tagging Words](https://www.nltk.org/book/ch05.html)\n",
    "\n",
    "[collocations](https://www.nltk.org/howto/collocations.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most common ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.collocations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('city', 'pop', 'real'),\n ('city', 'pop', 'icing'),\n ('city', 'pop', 'influence'),\n ('city', 'pop', 'permit'),\n ('sucker', 'city', 'pop'),\n ('city', 'pop', 'catch'),\n ('city', 'pop', 'lately'),\n ('city', 'pop', 'term'),\n ('considered', 'city', 'pop'),\n ('fall', 'city', 'pop'),\n ('siren', 'city', 'pop'),\n ('sounding', 'city', 'pop'),\n ('term', 'city', 'pop'),\n ('ton', 'city', 'pop'),\n ('defend', 'city', 'pop'),\n ('game', 'city', 'pop'),\n ('using', 'city', 'pop'),\n ('red', 'velvet', 'leaders'),\n ('😄😆', 'red', 'velvet'),\n ('example', 'city', 'pop'),\n ('hear', 'city', 'pop'),\n ('quite', 'city', 'pop'),\n ('call', 'city', 'pop'),\n ('city', 'pop', 'like'),\n ('red', 'velvet', 'listener'),\n ('need', 'city', 'pop'),\n ('city', 'pop', 'excited'),\n ('casual', 'red', 'velvet'),\n ('perhaps', 'red', 'velvet'),\n ('red', 'velvet', 'oldest'),\n ('irene', 'red', 'velvet'),\n ('city', 'pop', 'well'),\n ('city', 'pop', 'even'),\n ('expecting', 'red', 'velvet'),\n ('red', 'velvet', 'promote'),\n ('red', 'velvet', 'stick'),\n ('snsd', 'red', 'velvet'),\n ('red', 'velvet', 'dumb'),\n ('city', 'pop', \"i'm\"),\n ('city', 'pop', 'really'),\n ('red', 'velvet', 'lead'),\n ('red', 'velvet', 'vs'),\n ('comment', 'red', 'velvet'),\n ('industry', 'red', 'velvet'),\n ('use', 'red', 'velvet'),\n ('agree', 'red', 'velvet'),\n ('red', 'velvet', 'genre'),\n ('red', 'velvet', 'excited'),\n ('love', 'red', 'velvet'),\n ('red', 'velvet', 'members')]"
     },
     "metadata": {},
     "execution_count": 336
    }
   ],
   "source": [
    "top_ngrams(female_giant_comment_string, num_of_words=50, ngram=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('defending', 'stray', 'kids'),\n ('discussion', 'stray', 'kids'),\n ('familiar', 'stray', 'kids'),\n ('perception', 'stray', 'kids'),\n ('stray', 'kids', 'crackhead'),\n ('stray', 'kids', 'draws'),\n ('stray', 'kids', 'objectively'),\n ('stray', 'kids', 'touring'),\n ('stray', 'kids', 'specifically'),\n ('opinion', 'stray', 'kids'),\n ('stray', 'kids', 'called'),\n ('stray', 'kids', 'marketed'),\n ('blm', 'stray', 'kids'),\n ('point', 'stray', 'kids'),\n ('stray', 'kids', 'group'),\n ('groups', 'stray', 'kids'),\n ('love', 'stray', 'kids'),\n ('stray', 'kids', 'would'),\n ('culture', 'stray', 'kids'),\n ('stray', 'kids', \"i'm\"),\n ('hip', 'hop', 'rap'),\n ('features', 'hip', 'hop'),\n ('hoping', 'hip', 'hop'),\n ('consider', 'hip', 'hop'),\n ('hip', 'hop', 'banger'),\n ('american', 'hip', 'hop'),\n ('hip', 'hop', 'pop'),\n ('also', 'hip', 'hop'),\n ('find', 'new', 'home'),\n ('pretty', 'much', 'contained'),\n ('almost', 'pretty', 'much'),\n ('bans', 'depending', 'severity'),\n ('concert', 'entails', 'proper'),\n ('entails', 'proper', 'guidelines'),\n ('permanent', 'bans', 'depending'),\n ('temporary', 'permanent', 'bans'),\n ('also', 'discussed', 'posibble'),\n ('guidelines', 'also', 'discussed'),\n ('present', 'also', 'discussed'),\n ('guys', 'really', 'insensitive'),\n ('exo', 'sc', 'possibe'),\n ('opposite', 'exo', 'sc'),\n ('teamin', 'exo', 'sc'),\n ('heavily', 'black', 'culture'),\n ('depending', 'severity', 'actions'),\n ('hurl', 'meaningless', 'insults'),\n ('launch', 'search', 'party'),\n ('lived', 'western', 'countries'),\n ('please', 'continue', 'showing'),\n ('action', 'temporary', 'permanent')]"
     },
     "metadata": {},
     "execution_count": 338
    }
   ],
   "source": [
    "top_ngrams(male_giant_comment_string, num_of_words=50, ngram=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most common adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('good', 46),\n ('much', 39),\n ('new', 37),\n ('different', 35),\n ('korean', 32),\n ('many', 25),\n (\"i'm\", 24),\n ('bad', 23),\n ('japanese', 19),\n ('similar', 18),\n ('english', 18),\n ('first', 17),\n ('last', 17),\n ('happy', 16),\n ('great', 16),\n ('big', 16),\n ('lol', 15),\n ('it’s', 15),\n ('right', 15),\n ('sure', 15),\n ('full', 14),\n ('favorite', 13),\n ('single', 13),\n ('whole', 12),\n ('weird', 12),\n ('little', 12),\n ('wrong', 11),\n ('amazing', 11),\n ('real', 11),\n ('american', 11),\n ('popular', 11),\n ('long', 11),\n ('high', 11),\n ('red', 10),\n ('international', 10),\n ('sad', 10),\n ('top', 10),\n ('ready', 10),\n ('cute', 9),\n ('hard', 9),\n ('i’m', 9),\n ('mean', 9),\n ('main', 8),\n ('original', 8),\n ('give', 8),\n ('western', 8),\n ('song', 8),\n ('stupid', 7),\n ('aware', 7),\n (\"that's\", 7)]"
     },
     "metadata": {},
     "execution_count": 335
    }
   ],
   "source": [
    "most_common_adjectives(female_giant_comment_string, n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('much', 26),\n ('black', 22),\n ('happy', 19),\n ('new', 16),\n (\"i'm\", 15),\n ('western', 13),\n ('different', 12),\n ('sure', 12),\n ('american', 12),\n ('korean', 12),\n ('good', 11),\n ('last', 11),\n ('big', 11),\n ('old', 11),\n ('many', 10),\n ('first', 10),\n ('great', 10),\n ('right', 9),\n (\"that's\", 9),\n ('little', 8),\n ('open', 8),\n ('wrong', 7),\n ('whole', 6),\n ('long', 6),\n ('it’s', 6),\n ('cultural', 6),\n ('live', 6),\n ('sm', 6),\n ('asian', 6),\n ('clear', 6),\n ('bad', 6),\n ('i’m', 5),\n ('hard', 5),\n ('specific', 5),\n ('bts', 5),\n ('shit', 5),\n ('likely', 5),\n ('exo', 4),\n ('next', 4),\n ('proud', 4),\n ('iconic', 4),\n ('amazing', 4),\n ('true', 4),\n (\"can't\", 4),\n ('nct', 4),\n ('anniversary', 4),\n ('thank', 4),\n ('nice', 4),\n ('huge', 4),\n ('fair', 4)]"
     },
     "metadata": {},
     "execution_count": 334
    }
   ],
   "source": [
    "most_common_adjectives(male_giant_comment_string, n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1595475332605",
   "display_name": "Python 3.8.3 64-bit ('gendered-discussion': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}