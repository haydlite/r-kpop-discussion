{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planning / Scratch Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do /r/kpop commenters talk differently about male vs. female groups?\n",
    "\n",
    "Initial exploration of this question:\n",
    "- Identify submissions on 2 all-male groups, 2 all-female groups\n",
    "- Collect their comments\n",
    "- Contrast comments in general to \"typical\" reddit language (using /r/funny as a standard)\n",
    "- Contrast comments on male group vs female group "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Maybe separate analysis for emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Pushshift to get reddit comments\n",
    "\n",
    "See [Pushshift's GitHub API README](https://github.com/pushshift/api)\n",
    "\n",
    "> Search for the most recent comments mentioning the word \"science\" within the subreddit /r/askscience\n",
    ">\n",
    "> `https://api.pushshift.io/reddit/search/comment/?q=science&subreddit=askscience`\n",
    "\n",
    "Retrieve all comment ids for a submission object\n",
    "\n",
    "`https://api.pushshift.io/reddit/submission/comment_ids/{base36_submission_id}`\n",
    "\n",
    "[New to Pushshift FAQ](https://www.reddit.com/r/pushshift/comments/bcxguf/new_to_pushshift_read_this_faq/)\n",
    "\n",
    "[Pushshift Reddit API v4.0 Documentation](https://reddit-api.readthedocs.io/en/latest/#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not-comprehensive related works:\n",
    "- \"A Community of Curious Souls: An Analysis of Commenting Behavior on TED Talks Videos\" (Tsou, Thelwall, Mongeon, and Sugimoto, 2014)\n",
    "- \"YouTube science channel video presenters and comments: female friendly or vestiges of sexism?\" (Thelwall and Mas-Bleda, 2018)\n",
    "- \"Shirtless and dangerous: Quantifying linguistic signals of gender bias in an online fiction writing community.\" (Fast, Vachovsky, and Bernstein, 2016)\n",
    "- \"Using language models to quantify gender bias in sports journalism\" (Fu, Danescu-Niculescu-Mizil, Lee, 2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import requests\n",
    "import logging\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "ENGLISH_STOPWORDS = stopwords.words('english')\n",
    "\n",
    "import data_collection_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'data/comments/dncyvd-50'"
     },
     "metadata": {},
     "execution_count": 102
    }
   ],
   "source": [
    "filename[:23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "comments = {}\n",
    "for filename in glob.glob('data/comments/*-500-comments.pkl'):\n",
    "    start = filename.rindex('/') + 1\n",
    "    post_id = filename[start:start+6]\n",
    "    comments[post_id] = data_collection_utils.load_data(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collection_utils.save_data(comments, 'data/rkpop-1000-posts-comments.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = data_collection_utils.load_data('data/rkpop-1000-posts.pkl')\n",
    "post_ids = [p['id'] for p in posts]\n",
    "post_titles = [p['title'] for p in posts]\n",
    "\n",
    "post_ids_titles_dict = dict(zip(post_ids, post_titles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading from saved CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments_from_obj(post_id):\n",
    "    if post_id in comments:\n",
    "        return comments[post_id]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         id                                              title  \\\n0    hxhvbk  Mamamoo Wheein - Candy (orig. Baekhyun) (Speci...   \n1    hxekwy  Red Velvet - IRENE &amp; SEULGI - Monster (Two...   \n2    hxc2tq  BLACKPINK Lisa Appointed as Ambassador for BVL...   \n3    hx9kq3  The Rolling Stone included 9 K-Pop Boygroup so...   \n4    hx3a8s  PURPLE K!SS - Debut Trailer : WH0 CARES? - Ïú†ÌÇ§ ...   \n..      ...                                                ...   \n995  cul56i  BTS‚Äô Map Of The Soul: Persona is Now Riaa Cert...   \n996  cuge9n        What headline would you love to wake up to?   \n997  cuew53                     Congrats r/kpop for 400k subs!   \n998  cud85y  Comeback Stage: Red Velvet - Umpah Umpah (ÏùåÌååÏùåÌåå...   \n999  cubq93  2019 Soribada Awards Winners and Performances ...   \n\n                                              comments  \n0    [I'm so happy she didn't change the pronouns, ...  \n1    [RV never ever created a bad song, let alone a...  \n2    [count me in, what about Hera?, anyone partner...  \n3    [Lol @ the strawman, Man I'm reading through t...  \n4    [Yes Indeed, it\\`s a classic produce thing whe...  \n..                                                 ...  \n995  [Hmm, what does that mean for achievement thre...  \n996  [NCT 2019 ot21 yearbook and comeback, This com...  \n997  [No worries! üòä, That‚Äôs the top post over the l...  \n998  [I would have preferred this to be releases ea...  \n999  [Most Neverland are happy with what we got, no...  \n\n[1000 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>comments</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>hxhvbk</td>\n      <td>Mamamoo Wheein - Candy (orig. Baekhyun) (Speci...</td>\n      <td>[I'm so happy she didn't change the pronouns, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>hxekwy</td>\n      <td>Red Velvet - IRENE &amp;amp; SEULGI - Monster (Two...</td>\n      <td>[RV never ever created a bad song, let alone a...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>hxc2tq</td>\n      <td>BLACKPINK Lisa Appointed as Ambassador for BVL...</td>\n      <td>[count me in, what about Hera?, anyone partner...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>hx9kq3</td>\n      <td>The Rolling Stone included 9 K-Pop Boygroup so...</td>\n      <td>[Lol @ the strawman, Man I'm reading through t...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>hx3a8s</td>\n      <td>PURPLE K!SS - Debut Trailer : WH0 CARES? - Ïú†ÌÇ§ ...</td>\n      <td>[Yes Indeed, it\\`s a classic produce thing whe...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>cul56i</td>\n      <td>BTS‚Äô Map Of The Soul: Persona is Now Riaa Cert...</td>\n      <td>[Hmm, what does that mean for achievement thre...</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>cuge9n</td>\n      <td>What headline would you love to wake up to?</td>\n      <td>[NCT 2019 ot21 yearbook and comeback, This com...</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>cuew53</td>\n      <td>Congrats r/kpop for 400k subs!</td>\n      <td>[No worries! üòä, That‚Äôs the top post over the l...</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>cud85y</td>\n      <td>Comeback Stage: Red Velvet - Umpah Umpah (ÏùåÌååÏùåÌåå...</td>\n      <td>[I would have preferred this to be releases ea...</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>cubq93</td>\n      <td>2019 Soribada Awards Winners and Performances ...</td>\n      <td>[Most Neverland are happy with what we got, no...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows √ó 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 111
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(post_ids_titles_dict, orient='index')\n",
    "comments_as_series = df.reset_index()['index'].apply(lambda post_id: get_comments_from_obj(post_id))\n",
    "df = df.reset_index()\n",
    "df['comments'] = comments_as_series\n",
    "df.columns = ['id', 'title', 'comments']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/rkpop-data-id-title-comments-2020-08-01.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('data/rkpop-data-id-title-comments-2020-08-01.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify male vs female groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Map entities within comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m_f_mapping = {'male': {'male idols', 'male soloists' 'boy group', 'boygroup', 'boy', 'EXO', \n",
    "                        'NCT', 'BTS', 'Stray Kids', 'G-Dragon', 'Big Bang', \n",
    "                        'AB6IX', 'Golden Child', 'SEVENTEEN', 'Top Secret', 'TST', \n",
    "                        'ONEUS', 'TVXQ', 'PENTAGON', 'THE BOYZ', 'VERIVERY', 'Ravi', \n",
    "                        'WayV', 'VIXX', 'Super Junior', 'SHINee', 'Monsta X',\n",
    "                        'Block B', 'Zico', 'Treasure', 'J.Y Park', 'ATEEZ', 'iKON',\n",
    "                        'TXT', 'TOMORROW X TOGETHER', 'Jay Park', 'SuperM', 'GOT7', 'Dawn', 'X1',\n",
    "                        'BIGBANG', 'D-Crunch', 'Kingdom', 'Epik High', 'Day6', 'Winner', 'Shinhwa',\n",
    "                        'GDragon', 'Daesung', 'Taemin', 'Kang Daniel', 'J-Hope', 'Sleepy', 'OnlyOneOf',\n",
    "                        'Jackson Wang', 'Jungkook', 'B.I', 'IN2IT', '2PM', 'Super M', 'J.Y. Park',\n",
    "                        'CNBLUE', 'Seungri', 'Aoora'},\n",
    "\n",
    "               'female': {'female idols', 'female soloists', 'girlgroup', 'girl group', \n",
    "               'girl', 'GFriend', \"Girl's Day\", 'Red Velvet', 'AOA', 'BLACKPINK', \n",
    "               'Momoland', 'miss A', 'MAMAMOO', 'ITZY', 'Sunmi', 'Weeekly', 'NiziU', \n",
    "               'NATTY', 'Twice', 'LOONA', 'After School', 'IU', 'IZ*ONE', 'WJSN', \n",
    "               'Cosmic Girls', 'DIA', 'CHUNGHA', 'SNSD', 'Cherry Bullet', 'Somi', \n",
    "               '(G)I-DLE', 'Apink', 'Yukika', 'Oh My Girl', 'Lee Hi',\n",
    "               'PURPLE K!SS', 'Singer Minty', 'Rocket Punch', 'SISTAR', 'APRIL',\n",
    "               'Dreamcatcher', 'Secret', 'GWSN', 'pristin', 'Minah', 'Taeyeon',\n",
    "                'Girls Generation', '2NE1', 'Gong Minzy', 'Gugudan', 'Amber', 'f(x)',\n",
    "                'Crayon Pop', 'Hyuna', 'HINAPIA', 'BVNDIT', 'I.O.I.', 'Queendom', 'Alexa',\n",
    "                'LOOŒ†Œî', 'Sulli', 'Park Jimin', 'Jamie', 'PinkFantasy', 'Mina',\n",
    "                'Weki Meki', 'Tiffany Young', 'Jessica Jung', 'Ladies\\' Code', 'CLC',\n",
    "                'J-Min', 'Kyla Massie', 'Everglow', 'fromis_9', 'BOL4', 'Baek A Yeon', \n",
    "                'Park Bom', 'Idol School', 'IOI', 'EXID', 'BoA'},\n",
    "                \n",
    "                'mixed': {'AKMU', 'KARD'}\n",
    "}\n",
    "m_f_mapping['male'] = {g.lower() for g in m_f_mapping['male']}\n",
    "m_f_mapping['female'] = {g.lower() for g in m_f_mapping['female']}\n",
    "\n",
    "data_df['male'] = data_df['title'].apply(lambda t: any(group in t.lower() for group in m_f_mapping['male']))\n",
    "data_df['female'] = data_df['title'].apply(lambda t: any(group in t.lower() for group in m_f_mapping['female']))\n",
    "# # Checking if any overlapping...\n",
    "# data_df[data_df['male'] & data_df['female']]\n",
    "\n",
    "subset = data_df[  ~(data_df['male'] | data_df['female'])  ]\n",
    "# print(len(subset)) # len left to sorT\n",
    "# sorting\n",
    "# start = 202\n",
    "# width = 20\n",
    "# subset[['id', 'title']][start:start+width]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tag submissions with male or female"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean comment text and prepare for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "736\n"
    }
   ],
   "source": [
    "data_df_subset = data_df[((data_df['male']) | (data_df['female'])) & data_df['comments']] # Keep only comments w either male or female TRUE & comments are available\n",
    "data_df_subset = data_df_subset[ ~(data_df_subset['male'] & data_df_subset['female']) ] # Removes overlapping\n",
    "print(len(data_df_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       id  \\\n0  hxhvbk   \n1  hxekwy   \n2  hxc2tq   \n3  hx9kq3   \n4  hx3a8s   \n\n                                                                                                 title  \\\n0                                              Mamamoo Wheein - Candy (orig. Baekhyun) (Special video)   \n1                                          Red Velvet - IRENE &amp; SEULGI - Monster (Two Weeks Later)   \n2                                                   BLACKPINK Lisa Appointed as Ambassador for BVLGARI   \n3  The Rolling Stone included 9 K-Pop Boygroup songs into their \"75 Greatest Boyband Songs of Allti...   \n4                                                 PURPLE K!SS - Debut Trailer : WH0 CARES? - Ïú†ÌÇ§ (Yuki)   \n\n                                                                                              comments  \\\n0  [\"I'm so happy she didn't change the pronouns\", 'that last part is a question I think of almost ...   \n1  ['RV never ever created a bad song, let alone a bad album. \\nBut what shocked me the most has to...   \n2  ['count me in', 'what about Hera?', 'anyone partnering with Payless? /s', 'yes we can only affor...   \n3  ['Lol @ the strawman', \"Man I'm reading through this thread as a casual kpop fan and i was like ...   \n4  ['Yes Indeed, it\\\\`s a classic produce thing where some really talented people get eliminated pr...   \n\n    male  female  \n0  False    True  \n1  False    True  \n2  False    True  \n3   True   False  \n4  False    True  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>comments</th>\n      <th>male</th>\n      <th>female</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>hxhvbk</td>\n      <td>Mamamoo Wheein - Candy (orig. Baekhyun) (Special video)</td>\n      <td>[\"I'm so happy she didn't change the pronouns\", 'that last part is a question I think of almost ...</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>hxekwy</td>\n      <td>Red Velvet - IRENE &amp;amp; SEULGI - Monster (Two Weeks Later)</td>\n      <td>['RV never ever created a bad song, let alone a bad album. \\nBut what shocked me the most has to...</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>hxc2tq</td>\n      <td>BLACKPINK Lisa Appointed as Ambassador for BVLGARI</td>\n      <td>['count me in', 'what about Hera?', 'anyone partnering with Payless? /s', 'yes we can only affor...</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>hx9kq3</td>\n      <td>The Rolling Stone included 9 K-Pop Boygroup songs into their \"75 Greatest Boyband Songs of Allti...</td>\n      <td>['Lol @ the strawman', \"Man I'm reading through this thread as a casual kpop fan and i was like ...</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>hx3a8s</td>\n      <td>PURPLE K!SS - Debut Trailer : WH0 CARES? - Ïú†ÌÇ§ (Yuki)</td>\n      <td>['Yes Indeed, it\\\\`s a classic produce thing where some really talented people get eliminated pr...</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 212
    }
   ],
   "source": [
    "data_df_subset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[How to strip punctuation from a string](https://stackoverflow.com/questions/265960/best-way-to-strip-punctuation-from-a-string)\n",
    "\n",
    "`s.translate(str.maketrans('', '', string.punctuation))`\n",
    "\n",
    "[`maketrans` documentation](https://docs.python.org/3.3/library/stdtypes.html?highlight=maketrans#str.maketrans)\n",
    "\n",
    "[Removing URLs from a string](https://stackoverflow.com/questions/11331982/how-to-remove-any-url-within-a-string-in-python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def giant_cleaned_string(series_of_list_of_comments):\n",
    "    \"\"\"Return string from Pandas Series of lists of strings.\n",
    "    \n",
    "    Combines multiple pandas rows with lists of strings into one giant string with URLs and punctuation removed.\n",
    "    \"\"\"\n",
    "    comment_string = ' '.join(series_of_list_of_comments.apply(lambda x: ' '.join(x.split())))\n",
    "    comment_string = re.sub('http://\\S+|https://\\S+', '', comment_string)\n",
    "\n",
    "    chars_to_replace = string.punctuation[:6]+string.punctuation[7:]+'‚Äú‚Äù\\n' # Don't remove single quotation mark\n",
    "    whitespace_to_replace_with = len(chars_to_replace) * ' '\n",
    "\n",
    "    comment_string = comment_string.lower().translate(str.maketrans(chars_to_replace, whitespace_to_replace_with))\n",
    "    return comment_string\n",
    "\n",
    "def acceptable_token(token):\n",
    "    \"\"\" Return True if token is longer than one character and is not present in ENGLISH_STOPWORDS\n",
    "    \"\"\"\n",
    "    return (len(token) > 1 and token not in ENGLISH_STOPWORDS)\n",
    "\n",
    "def tokenize(giant_comment_string):\n",
    "    \"\"\" Return list of word tokens from given string.\n",
    "    \"\"\"\n",
    "    tokens = giant_comment_string.split(' ')\n",
    "    return list(filter(acceptable_token, tokens))\n",
    "\n",
    "def create_counter_object(giant_comment_string):\n",
    "    \"\"\" Return Counter with word counters for given string.\n",
    "    \"\"\"\n",
    "    word_counter = Counter(tokenize(giant_comment_string))\n",
    "    return word_counter\n",
    "\n",
    "def top_adjectives(giant_comment_string, num_of_words=10):\n",
    "    \"\"\" Return list with most common adjectives in given string.\n",
    "    \"\"\"\n",
    "\n",
    "    def find_adjectives(list_of_word_pos_tuple):\n",
    "        return list_of_word_pos_tuple[1] == 'JJ'\n",
    "\n",
    "    comment_words_POS = nltk.pos_tag(tokenize(giant_comment_string))\n",
    "    comment_adj_counter = Counter([adj[0] for adj in list(filter(find_adjectives, comment_words_POS))])\n",
    "    return comment_adj_counter.most_common(num_of_words)\n",
    "\n",
    "# TODO: Determine association metric to use\n",
    "# http://www.nltk.org/_modules/nltk/metrics/association.html\n",
    "def top_ngrams(giant_comment_string, top_n=15, ngram=2):\n",
    "    \"\"\" Return top-n sized list with most frequently appearing n-grams in given string.\n",
    "    \"\"\"\n",
    "\n",
    "    if ngram == 2:\n",
    "        finder = BigramCollocationFinder.from_words(tokenize(giant_comment_string))\n",
    "        return finder.nbest(bigram_measures.likelihood_ratio, top_n)\n",
    "    elif ngram == 3:\n",
    "        finder = TrigramCollocationFinder.from_words(tokenize(giant_comment_string))\n",
    "        return finder.nbest(trigram_measures.likelihood_ratio, top_n)\n",
    "    else:\n",
    "        return \"Error: Only bi- and trigrams supported.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Move analysis helper function into their own py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_giant_comment_string = giant_cleaned_string(data_df_subset['comments'])\n",
    "overall_word_counter = create_counter_object(overall_giant_comment_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_giant_comment_string = giant_cleaned_string(data_df_subset[data_df_subset['male']]['comments'])\n",
    "female_giant_comment_string = giant_cleaned_string(data_df_subset[data_df_subset['female']]['comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_word_counter = create_counter_object(female_giant_comment_string)\n",
    "male_word_counter = create_counter_object(male_giant_comment_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1127531"
     },
     "metadata": {},
     "execution_count": 217
    }
   ],
   "source": [
    "sum(overall_word_counter.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "692335"
     },
     "metadata": {},
     "execution_count": 218
    }
   ],
   "source": [
    "sum(female_word_counter.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "435196"
     },
     "metadata": {},
     "execution_count": 219
    }
   ],
   "source": [
    "sum(male_word_counter.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Log-Odds Ratio of Words\n",
    "# len(male_giant_comment_string.split(' ')) # 6718 \n",
    "# len(female_giant_comment_string.split(' ')) # 14882"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "overall_top_50 = overall_word_counter.most_common(50)\n",
    "male_top_50 = male_word_counter.most_common(50)\n",
    "female_top_50 = female_word_counter.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[('like', 13156), ('really', 7572), ('one', 6644), ('think', 6481), ('people', 6263), ('song', 6134), ('even', 5389), (\"i'm\", 5344), ('would', 5163), (\"'s\", 4909), ('get', 4855), ('group', 4854), ('know', 4691), ('love', 4525), (\"'i\", 4356), ('also', 4302), ('time', 4246), ('see', 4185), ('good', 4170), ('much', 4085), ('still', 4035), (\"'t\", 3729), ('well', 3439), ('kpop', 3317), ('music', 3196), ('album', 3194), ('going', 3036), ('fans', 3004), ('gt', 2879), ('way', 2865), ('first', 2821), ('songs', 2804), ('make', 2732), ('groups', 2682), ('since', 2592), ('got', 2592), ('lot', 2584), ('say', 2581), ('something', 2555), ('want', 2488), ('feel', 2473), ('go', 2457), ('said', 2438), ('back', 2412), ('could', 2392), ('ni', 2384), ('year', 2351), ('show', 2326), ('actually', 2237), ('right', 2236)]\n\n[('like', 5068), ('really', 2829), ('people', 2597), ('think', 2506), ('one', 2469), (\"'s\", 2152), ('song', 2142), ('even', 2089), (\"i'm\", 2087), ('get', 2003), ('know', 1938), ('group', 1878), ('would', 1868), ('also', 1705), ('see', 1650), (\"'t\", 1604), ('time', 1601), ('love', 1585), (\"'i\", 1581), ('good', 1572), ('still', 1547), ('much', 1485), ('fans', 1448), ('album', 1401), ('kpop', 1299), ('music', 1285), ('well', 1285), ('going', 1282), ('gt', 1213), ('way', 1177), ('make', 1105), ('first', 1088), ('sm', 1079), ('say', 1070), ('said', 1068), ('bts', 1034), ('want', 1030), ('lot', 995), ('go', 991), ('since', 976), ('something', 961), ('ni', 950), ('got', 939), ('back', 932), ('us', 932), ('right', 918), ('feel', 911), ('it‚Äôs', 902), ('songs', 898), ('could', 893)]\n\n[('like', 8088), ('really', 4743), ('one', 4175), ('song', 3992), ('think', 3975), ('people', 3666), ('even', 3300), ('would', 3295), (\"i'm\", 3257), ('group', 2976), ('love', 2940), ('get', 2852), (\"'i\", 2775), (\"'s\", 2757), ('know', 2753), ('time', 2645), ('much', 2600), ('good', 2598), ('also', 2597), ('see', 2535), ('still', 2488), ('well', 2154), (\"'t\", 2125), ('kpop', 2018), ('music', 1911), ('songs', 1906), ('groups', 1830), ('album', 1793), ('going', 1754), ('first', 1733), ('way', 1688), ('show', 1674), ('gt', 1666), ('got', 1653), ('make', 1627), ('since', 1616), ('something', 1594), ('lot', 1589), ('feel', 1562), ('fans', 1556), ('year', 1539), ('say', 1511), ('could', 1499), ('girl', 1499), ('back', 1480), ('comeback', 1476), ('go', 1466), ('want', 1458), ('twice', 1446), ('ni', 1434)]\n"
    }
   ],
   "source": [
    "print(overall_top_50)\n",
    "print()\n",
    "print(male_top_50)\n",
    "print()\n",
    "print(female_top_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fix words that start with an apostrophe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_male_words = set(male_word_counter.keys()) - set(female_word_counter.keys())\n",
    "unique_female_words = set(female_word_counter.keys()) - set(male_word_counter.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "queer: 28\nmeat: 20\nshindong: 13\nfender: 14\nbrockhampton: 11\njisung: 14\nhe‚Äôll: 11\nriyadh: 14\nhe‚Äòs: 14\nbeomgyu: 21\nntaemin: 14\nsherlock: 18\nthanksgiving: 14\ntaeyong's: 19\nptg: 12\nyoungk: 12\ntangled: 13\nyeonjun: 30\nboys24: 13\nweishennies: 12\njeonghan: 19\ndanity: 29\ndonghae: 12\nhendery: 36\nxiaojun: 41\ndaeun: 38\nfanship: 11\nseungkwan: 14\nbv: 11\nhakka: 16\ninterlude: 12\nmihawk: 14\njooheon: 22\nkihyun: 23\nkun: 35\n'nct: 14\nmolka: 18\n127's: 12\nmonbebes: 12\nseungyoun: 30\nhongjoong: 17\nexols: 25\njuvie: 13\nhwanwoong: 18\nnick: 19\npuma: 28\naoora: 12\nbasquiat: 18\nrtk: 48\nten's: 28\njoshua: 14\npension: 13\nycmn: 11\nwayv's: 12\nwonwoo: 12\nnipples: 14\ncowell: 14\nmarkyong: 13\nmonarchs: 11\nnctzen: 16\natinys: 16\nicstr: 17\nthermal: 12\nyun: 14\nseohee: 12\nmoa: 16\nlm: 49\nyesung: 16\ncctv: 12\nviolations: 11\nthanxx: 23\nmist: 17\nyangyang: 30\ncapitol: 72\nmingi: 30\njongin: 16\ncjh: 13\nmark's: 29\ncorden: 19\nseonghwa: 11\nlauv: 16\nbackstreet: 11\nsr: 18\ncaa: 11\ndrivers: 13\nwonho's: 18\n3racha: 13\ndramarama: 24\nseoho: 15\nyeosang: 17\nmonbebe: 25\nsentenced: 12\n'ten: 22\n'baekhyun: 21\nhsh: 53\nkaibaek: 23\ndubai: 12\nin2it: 14\nsungjin: 12\ngh: 15\nbenji: 19\ntbz: 20\nchapter: 12\n1d: 24\nminhee: 11\nhyungwon: 29\nbrr: 12\nmoonwalk: 15\njde: 19\n"
    }
   ],
   "source": [
    "for word in unique_male_words:\n",
    "    if male_word_counter[word] > 10:\n",
    "        print('{}: {}'.format(word, male_word_counter[word]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "hocus: 18\n'clc: 11\ntwicelights: 14\ngsd: 12\ncrayon: 30\namber's: 17\n'somi: 15\nblusher: 14\njennie's: 28\nchuu: 25\nhayi: 13\naviation: 22\nnayeon's: 18\n'tzuyu: 13\nmoonbyul: 71\nbangle: 15\njamming: 12\nladies': 12\ncowboy: 18\nsailor: 15\nminyoung: 19\ndetroit: 11\nonces: 60\ngimmicks: 15\n'seulgi: 14\nchu: 22\n'queens: 18\ngaeun: 12\nhyolyn: 17\njea: 15\nsunhwa: 13\nnbom: 17\nponytail: 26\nrouge: 14\nwheein: 98\nyoojung: 37\nnayeon: 162\n'irene: 14\n'chaeyoung: 12\nmina‚Äôs: 15\ncondolences: 15\nflo: 17\ntilapia: 13\ncignature: 12\nyeoreum: 14\nyves: 32\nlackluster: 15\ntaeha: 33\ndlwlrma: 17\nnugus: 16\ndumhdurum: 14\nhappyface: 17\nyeri: 70\nalex: 12\nakali: 19\nrussian: 41\ndiets: 49\nyiren: 14\nmospick: 11\nwengie: 12\nssak3: 14\nmimi's: 13\nrealtime: 16\n'sana: 24\nollounder: 22\nneon: 35\ntwitch: 19\nsian: 32\ndart: 15\ntweaks: 34\nseunghee: 72\njieun: 34\nconi: 15\ndahyun's: 13\nlipa: 13\nyujin: 51\nsolar's: 12\nyuqi's: 11\nbazooka: 29\nloonatic: 25\nmomo's: 28\noverweight: 16\nnako: 28\ndkdk: 79\norbit: 14\nyein: 28\nunderweight: 24\nlions: 14\naires: 17\nminju: 19\nmimi: 56\nhandong: 57\njakku: 13\niggy: 14\nhwasa's: 19\nmorte: 12\nqueens': 17\ntoktok: 13\nyaebin: 23\njihyo's: 25\ndoni: 18\nsana's: 23\nlovelyz: 357\nlc: 19\nrugby: 19\nchaewon: 22\nwonderboy: 13\npromises: 11\nchaeyoung: 127\n6y: 12\nvita: 12\nshe‚Äôll: 23\nrendezvous: 13\nsujeong: 20\njooe: 24\nsejeong: 28\nrv's: 22\n'aoa: 26\nvvip: 16\nyyxy: 19\npinocchio: 61\ngorgeous': 11\nlove4eva: 23\nping: 16\n4minute: 33\nbaam: 13\ncbt: 11\nchaeyoung's: 16\nsulli‚Äôs: 26\n'iu: 14\nhyeri: 15\negoist: 48\nirene's: 18\nstarvation: 21\nsoojin's: 16\ndaisy's: 13\nnbsp: 30\nsakura: 34\nhitomi: 12\nbora: 13\np48: 15\nireh: 15\nnancy: 50\nbuenos: 15\nidle‚Äôs: 11\nnscroll: 21\nnoir: 21\nstrawberry: 13\nmerry: 15\nnmina: 16\nmall: 11\nloopy: 17\ncheetah: 25\nmina': 11\ngothic: 19\nidle's: 23\nmamamoo‚Äôs: 13\nextensions: 25\nreve: 19\nlovelinus: 11\nnlovelyz: 24\nbassline: 15\nrose's: 11\nstarry: 17\nmoomoos: 28\nroyal: 13\nsiyeon's: 21\nbbibbi: 20\nnsoyeon: 11\nbmi: 14\niu's: 14\nyolowa: 17\nvioleta: 14\nstarve: 17\nyoohyeon: 54\nchae: 39\nmiyeon: 99\nhaein: 43\npong: 14\nspider: 23\nlalalay: 15\nhinapia: 47\n'solar: 11\n'dahyun: 17\nroa: 25\naustin: 11\npasswords: 11\nchaeyeon: 37\nperson's: 14\nburger: 12\nlovelyz's: 11\njiu: 67\nhobgoblin: 13\n'rest: 13\n021: 11\nmoomoo: 24\ndua: 13\nkaeun: 15\nindefinite: 15\nalready': 13\npum: 167\npocus: 18\nbada: 29\npepe: 19\ngyeongwon: 18\nminkyeung: 23\nyena: 23\nchoa: 65\n88rising: 14\npapi: 32\n'cube: 15\nhyojung: 62\nchanmi: 43\ngoeun: 23\ndtna: 23\nnodes: 16\n2am: 12\nshuhua's: 22\ntaengoo: 32\nnight': 13\nyuha: 13\nsoyeon's: 28\naks: 29\nbinnie: 29\nsua: 37\nmijoo: 11\nbbi: 28\nnomg: 16\np101: 30\nunpretty: 13\nyooa: 90\n'soyeon: 41\nroulette: 29\npassword: 12\n'mina: 34\nrumpumpum: 58\n22century: 42\nakb: 12\njaysus: 15\nsoshi: 13\n'amber: 14\nseunghee's: 12\npinky: 46\nwendy's: 14\nrum: 60\nfined: 11\nbna: 12\nnaoa: 25\nfries: 11\nkokoro: 26\nhostess: 11\nheejin: 13\nmaria: 18\nglowing: 16\nbyul: 18\n'jeongyeon: 26\nreveluvs: 20\ncronodroid: 11\nsinb: 18\ndecalcomanie: 13\nbrian: 44\nhayoung: 32\npuss: 16\neunji: 15\n'soojin: 17\nsoojin: 111\nmeu: 12\n4walls: 11\nfrequency: 13\ngiveaway: 26\nmiryo: 19\nchristian: 12\njuri: 15\n2fa: 18\nyunjin: 24\n„Öã„Öã„Öã„Öã: 67\nbdz: 28\ngroo: 11\nlisa's: 19\nyukika: 36\n'nayeon: 16\n'shes: 11\nchoerry: 14\n'hwasa: 13\nnsulli: 16\ngahyeon: 30\ntwinkle: 17\njoyuriz: 15\n'moonbyul: 12\nsonatine: 24\nfillers: 34\nbom's: 29\nminkyung: 11\nminji: 11\nyeeun: 35\ndddd: 13\nmld: 56\n'lovelyz: 13\nbp‚Äôs: 12\nnatty: 50\nchungha's: 14\nfc: 12\nyuehua: 23\njoints: 20\nsiyeon: 87\naerialist: 18\ntaeyeons: 13\nmoonbyul's: 16\nnina: 12\ncube's: 13\ntwice': 25\njoji: 15\nhani: 14\naoa‚Äôs: 16\ndoxie: 11\nrosy: 20\nbingle: 12\nsana': 12\nprincess: 28\n'fancy: 15\nnshe's: 16\nweeekly: 11\nlinlin: 17\nseulgi's: 15\nparticipant: 13\nn‚Ä¢: 15\nclover: 40\nhyosung: 12\n'mamamoo: 41\nmoderation: 17\ngashina: 16\ndracula: 31\nconcussion: 11\nchaeng: 20\n"
    }
   ],
   "source": [
    "for word in unique_female_words:\n",
    "    if female_word_counter[word] > 10:\n",
    "        print('{}: {}'.format(word, female_word_counter[word]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_overall_words = set(overall_word_counter.keys()) - set(female_word_counter.keys()) - set(male_word_counter.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "set()"
     },
     "metadata": {},
     "execution_count": 225
    }
   ],
   "source": [
    "unique_overall_words # No words that showed up only in overall but in neither female nor male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_male_word_counter = Counter()\n",
    "unique_female_word_counter = Counter()\n",
    "\n",
    "for word in unique_male_words:\n",
    "    unique_male_word_counter[word] = male_word_counter[word] \n",
    "\n",
    "for word in unique_female_words:\n",
    "    unique_female_word_counter[word] = female_word_counter[word] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_male_words_str = ' '.join(unique_male_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_male_words_str = ' '.join(unique_male_words)\n",
    "unique_female_words_str = ' '.join(unique_female_words)\n",
    "unique_male_adj_tuples = list(filter(lambda x: x[1]=='JJ', nltk.pos_tag(tokenize(unique_male_words_str)))) # filter for words uniquely used toward male groups/people AND are adjectives\n",
    "unique_female_adj_tuples = list(filter(lambda x: x[1]=='JJ', nltk.pos_tag(tokenize(unique_female_words_str)))) # filter for words uniquely used toward male groups/people AND are adjectives\n",
    "unique_male_adj = [tup[0] for tup in unique_male_adj_tuples]\n",
    "unique_female_adj = [tup[0] for tup in unique_female_adj_tuples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_male_adj_counter = Counter()\n",
    "unique_female_adj_counter = Counter()\n",
    "\n",
    "for word in unique_male_adj:\n",
    "    unique_male_adj_counter[word] = male_word_counter[word] \n",
    "\n",
    "for word in unique_female_adj:\n",
    "    unique_female_adj_counter[word] = female_word_counter[word] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[('mingi', 30), (\"'baekhyun\", 21), ('nick', 19), ('hwanwoong', 18), ('hongjoong', 17), ('atinys', 16), ('ntaemin', 14), (\"'nct\", 14), ('in2it', 14), ('shindong', 13), ('markyong', 13), ('interlude', 12), ('wonwoo', 12), ('thermal', 12), ('cctv', 12), ('sungjin', 12), ('he‚Äôll', 11), ('fanship', 11), ('bv', 11), ('wooyoung', 10), ('atiny', 9), ('gea', 9), ('jop', 9), ('upskirt', 9), (\"shownu's\", 8), ('ntaeyong', 8), (\"lucas'\", 8), ('unbreakable', 8), ('nsuperm', 8), ('ukpop', 7), ('nba', 7), (\"yeonjun's\", 7), ('unicef', 7), ('siento', 7), ('mbbs', 7), ('applicable', 7), ('nten', 7), ('hj', 7), (\"onf's\", 7), ('nateez', 7), ('locs', 7), (\"woojin's\", 7), ('dohyon', 7), ('yohan', 7), ('flush', 6), ('taeyong‚Äôs', 6), ('superm‚Äôs', 6), ('ungri', 6), ('ot21', 6), ('unimportant', 6), ('nwonho', 6), ('juliet', 6), ('turkish', 6), ('dohyun', 6), (\"utopia'\", 6), ('suhwan', 6), (\"namjoon's\", 5), ('nmonsta', 5), ('tmap', 5), ('noneus', 5), ('cwjltma', 5), ('nwoojin', 5), ('homoerotic', 5), ('nrun', 5), (\"jk's\", 5), ('bt21', 5), ('seungmin', 5), (\"hala'\", 5), ('njune', 5), ('nrm', 5), ('crawl', 5), ('taeten', 5), ('minimalistic', 5), ('superintendent', 5), ('shazam', 5), ('infringement', 5), ('ncheckmate', 5), ('dns', 5), ('usher', 5), ('hueningkai', 4), ('rub', 4), ('indisputable', 4), ('colonial', 4), (\"baekhyun'\", 4), ('remorseful', 4), ('accidental', 4), ('nembezzlement', 4), (\"weed'\", 4), ('explanatory', 4), ('nbasquiat', 4), ('hongjoong‚Äôs', 4), (\"l's\", 4), ('freshteen', 4), ('epitome', 4), ('iheart', 4), ('objectionable', 4), ('mcr', 4), ('vip‚Äôs', 4), ('politeness', 4), ('dada', 4)]\n"
    }
   ],
   "source": [
    "print(unique_male_adj_counter.most_common(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[('wheein', 98), ('seunghee', 72), ('moonbyul', 71), ('choa', 65), ('rumpumpum', 58), ('handong', 57), ('natty', 50), ('pinky', 46), ('brian', 44), ('chanmi', 43), ('russian', 41), ('sian', 32), ('papi', 32), ('nbsp', 30), ('bazooka', 29), (\"bom's\", 29), ('sejeong', 28), (\"soyeon's\", 28), ('princess', 28), ('loonatic', 25), ('naoa', 25), ('underweight', 24), ('love4eva', 23), (\"rv's\", 22), ('noir', 21), ('sujeong', 20), ('rosy', 20), (\"hwasa's\", 19), ('gothic', 19), (\"nayeon's\", 18), (\"amber's\", 17), ('nbom', 17), (\"queens'\", 17), ('loopy', 17), ('nugus', 16), (\"chaeyoung's\", 16), (\"soojin's\", 16), ('nodes', 16), ('nomg', 16), (\"nshe's\", 16), ('sailor', 15), ('lackluster', 15), ('ireh', 15), ('indefinite', 15), ('iggy', 14), ('wonderboy', 13), ('rendezvous', 13), ('unpretty', 13), ('participant', 13), ('alex', 12), ('bna', 12), ('christian', 12), ('nina', 12), ('bingle', 12), ('austin', 11), ('weeekly', 11), ('upward', 10), ('garnered', 10), (\"nancy's\", 10), ('wendy‚Äôs', 10), ('nhonorable', 10), ('eunbin', 10), ('wiz', 10), (\"dami's\", 9), ('insomnias', 9), ('unsolicited', 9), ('smngg', 9), (\"'miss\", 9), ('bom‚Äôs', 9), ('bim', 8), (\"pinocchio'\", 8), ('sogyeokdong', 8), ('haeyoon', 8), ('iwasetai', 8), ('ahin', 8), ('tender', 8), ('egoistic', 8), ('u202c', 8), ('tisdale', 8), (\"dc's\", 8), ('chiri', 8), ('girlcrush', 8), ('counterpart', 8), ('landslide', 8), ('gloomy', 8), ('oreo', 8), ('laurent', 7), (\"natty's\", 7), ('palmer', 7), ('console', 7), ('hyejin', 7), (\"'silent\", 7), ('narsha', 7), ('chengxiao', 7), ('mayday', 7), ('belive', 7), (\"miracle'\", 7), ('wisdom', 7), (\"'though\", 7), ('n12', 7)]\n"
    }
   ],
   "source": [
    "print(unique_female_adj_counter.most_common(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What adjectives are used? Verbs? \n",
    "\n",
    "[Categorizing and Tagging Words](https://www.nltk.org/book/ch05.html)\n",
    "\n",
    "[collocations](https://www.nltk.org/howto/collocations.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most common ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remove title tracks from ngram consideration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.collocations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_top_male_bigram_tuples = set(top_male_bigram_tuples)\n",
    "set_top_female_bigram_tuples = set(top_female_bigram_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "itar'), ('juvenile', 'detention'), ('seperate', 'rather'), ('physical', 'sales'), ('china', 'politically'), ('ngiving', 'level'), ('nap', 'star'), ('born', 'china'), ('inclined', 'take'), ('deep', 'breath'), ('getting', 'downvoted'), ('role', 'models'), ('critcism', 'nothing'), ('zero', 'lines'), ('consequences', 'half'), ('termination', 'fees'), ('half', 'ass'), ('dog', 'meat'), ('posted', 'siding'), ('understanding', 'situation'), ('line', 'born'), ('issue', 'ngiving'), ('black', 'suit'), ('take', 'advantage'), (\"can't\", 'survive'), ('city', 'lights'), ('urban', 'dictionary'), ('double', 'knot'), ('love', 'shot'), ('please', 'let'), ('rather', 'ironic'), ('thanksgiving', 'parade'), ('proven', 'guilty'), (\"'i\", 'can‚Äôt'), ('sexual', 'harassment'), ('don‚Äôt', 'want'), ('career', '2017'), ('hala', 'n2'), ('view', 'counts'), ('jackson', 'shitty'), ('new', 'world'), ('pearl', 'aqua'), ('street', 'team'), ('digital', 'downloads'), (\"we've\", 'seen'), ('rookie', 'award'), ('confession', 'apology'), ('american', 'market'), ('whatever', 'political'), ('hala', 'n6'), ('wave', 'n7'), ('posting', 'address'), ('hk', 'pride'), ('please', 'visit'), ('network', 'love'), ('nominated', 'rookie'), ('soompi', 'article'), ('person‚Äôs', 'career'), ('rap', 'line'), ('somewhere', 'else'), ('nsure', 'however'), ('n6', 'wave'), ('air', 'safety'), ('n5', 'hala'), ('weibo', 'held'), ('general', 'feedback'), ('ironic', 'issue'), ('pro', 'china'), ('couple', 'times'), ('umbrella', 'movement'), ('rap', 'heavy'), ('sexually', 'harassed'), ('americans', 'western'), ('tummy', 'fat'), ('many', 'years'), ('excuse', 'basically'), ('held', 'flag'), ('owes', 'money'), ('award', 'show'), ('mouse', 'club'), ('baby', 'stop'), ('charlie', 'puth'), ('musical', 'direction'), ('leaning', 'towards'), ('backstreet', 'boys'), ('casual', 'listener'), ('middle', 'eastern'), ('car', 'accident'), ('every', 'member'), ('ed', 'sheeran'), ('flower', 'shower'), ('pop', 'groups'), ('cancel', 'culture'), ('sm', 'capitol'), ('korean', 'fans'), ('cookie', 'cutter'), ('lana', 'del'), ('wayv', 'seventeen'), ('1b', 'views'), ('judge', 'everyone'), ('huening', 'kai'), ('change', 'fact'), ('leave', 'monster'), ('netz', 'known'), ('bot', 'nthis'), ('pop', 'music'), ('morse', 'code'), ('open', 'minded'), ('seventeen', 'line'), ('old', 'school'), ('role', 'model'), ('cat', 'amp'), ('grand', 'scheme'), ('career', 'nsure'), ('meow', 'meow'), ('simon', 'says'), (\"they're\", 'still'), ('nothing', 'else'), ('get', 'opportunities'), ('disappointed', 'views'), ('05', '49'), ('ni', 'reiterating'), ('500', '000'), ('absolutely', 'love'), ('good', 'idea'), ('cash', 'grab'), ('point', 'condoning'), ('united', 'version'), ('china', 'excuse'), ('blue', 'orangeade'), ('count', 'towards'), ('taking', 'stand'), ('late', 'night'), ('monkey', 'museum'), ('entirely', 'valid'), ('white', 'people'), ('nu', \"'est\"), ('put', 'together'), ('taemin', 'kai'), ('like', 'said'), ('renjun', 'chenle'), ('western', 'countries'), ('asian', 'countries'), ('200k', '300k'), ('jong', 'hyun'), ('name', 'n2'), ('intense', 'criticism'), ('least', 'upvotes'), ('country', 'promoting'), ('promoting', 'country'), ('etc', 'etc'), ('slap', 'face'), ('lgbt', 'community'), (\"'m\", 'saying'), ('non', 'fans'), ('nalso', 'tzuyu'), ('views', 'actions'), ('early', '2000s'), ('english', 'lyrics'), ('disney', 'nick'), ('floating', 'around'), ('deep', 'love'), ('oh', 'wow'), ('gel', 'twirls'), ('favour', 'get'), ('whole', 'album'), ('stop', 'talking'), ('chinese', 'flag'), ('chef', 'kiss'), ('stand', 'whatever'), ('1st', 'day'), ('fresh', 'air'), ('n10', \"utopia'\"), ('funk', 'styles'), ('entertainment', 'companies'), (\"utopia'\", \"'1\"), ('social', 'distancing'), ('relevant', 'excuse'), ('really', 'excited'), ('top', 'head'), ('making', 'money'), ('public', 'opinion'), ('trying', 'say'), ('michael', 'jackson'), ('hyyh', 'pt'), ('going', 'happen'), ('cj', 'amp'), ('bad', 'alive'), ('top', 'weekly'), ('held', 'major'), ('million', 'seller'), ('camera', 'work'), ('taxi', 'driver'), ('lee', 'jong'), ('lot', 'money'), ('don‚Äôt', 'see'), ('jackson', 'start'), ('ring', 'ding'), ('black', 'swan'), ('rookie', 'groups'), ('korean', 'artist'), ('debut', 'album'), ('sorry', 'sorry'), ('avant', 'garde'), ('bossa', 'nova'), ('goo', 'hara'), ('jinhwan', 'junhoe'), ('trying', 'get'), ('7th', 'sense'), ('release', 'date'), ('like', 'yuqi'), ('n4', 'utopia'), ('baekhyun', 'kai'), (\"'re\", 'talking'), ('native', 'speaker'), ('one', 'person'), ('song', 'sounds'), ('wannabe', 'without'), ('stalkers', 'nthe'), ('n10', \"treasure'\"), ('western', 'media'), ('avengers', 'kpop'), ('see', 'perform'), ('civil', 'rights'), ('criticism', 'entirely'), ('china', 'ultimately'), ('25', 'least'), ('aesthetically', 'pleasing'), ('taeyong', 'mark'), ('hk', 'taiwan'), ('address', 'posted'), ('treasure', 'n8'), (\"poppin'\", 'star'), ('saying', 'suck'), ('music', 'auto'), ('status', 'quo'), ('left', 'field'), ('desire', 'n8'), ('keep', 'mind'), ('n5', 'pirate'), ('guilt', 'tripping'), (\"macy's\", 'thanksgiving'), ('n7', 'treasure'), ('billboard', '200'), ('mentalities', 'experiences'), ('breath', 'fresh'), ('n7', 'desire'), ('media', 'play'), ('ceo', 'yang'), ('cancellation', 'fee'), ('real', 'estate'), ('promise', 'n4'), ('criticism', 'jackson'), ('idols', 'promoting'), ('49', '20z'), ('duluth', 'ga'), ('hideo', 'kojima'), ('statute', 'limitations'), ('since', '2014'), ('want', 'support'), ('innocent', 'proven'), ('performance', 'video'), ('go', 'ahead'), ('global', 'shop'), ('smart', 'move'), ('full', 'offensive'), ('idol', 'industry'), ('deleted', 'deleted'), ('flag', 'whatever'), ('core', 'fandom'), ('known', 'intense'), ('chat', 'rooms'), ('12am', 'kst'), ('jingle', 'ball'), ('speaks', 'volumes'), ('one', 'biggest'), ('three', 'months'), ('gotta', 'say'), ('n3', 'promise'), ('fandom', 'name'), ('last', 'two'), ('baekhyun', 'taemin'), ('monsta', 'x‚Äôs'), ('09', '22z'), ('iron', 'maiden'), ('sore', 'thumb'), ('someone', 'explain'), ('phase', '9th'), ('teaser', 'pics'), ('beginning', 'end'), ('drug', 'dealer'), ('monster', 'alive'), ('terminate', 'contract'), (\"what's\", 'wrong'), ('political', 'climate'), ('keep', 'going'), ('sun', 'scandal'), ('fight', 'death'), ('member', 'group'), ('gd', 'taeyang'), ('del', 'rey'), ('name', 'n3'), ('11', 'years'), ('light', 'mist'), ('least', 'favorite'), ('moonlight', 'sonata'), ('start', 'chinese'), (\"'t\", 'hostage'), ('end', 'stick'), ('middle', 'aged'), ('even', 'better'), (\"'t\", 'want'), ('high', 'budget'), ('opium', 'war'), ('war', 'bonnets'), ('agent', 'orange'), ('point', 'destroying'), ('cake', 'day'), ('Õú ñ', 'Õ°¬∞'), ('Õ°¬∞', 'Õú ñ'), ('taste', 'mouth'), ('take', 'stand'), ('wear', 'dreads'), ('hormone', 'therapy'), ('000', 'copies'), ('victim', 'complex'), ('king', 'n6'), ('poppin', 'star'), ('utopia', 'n5'), ('drug', 'tests'), ('another', 'group'), ('chemical', 'romance'), ('easter', 'eggs'), ('thing', 'americans'), ('excuse', 'actions'), ('chinese', 'solo'), ('aju', 'nice'), ('going', 'destroyed'), ('n8', 'pirate'), ('joon', 'young'), ('marching', 'band'), ('quantum', 'leap'), ('butt', 'biting'), ('low', 'budget'), ('n10', \"aurora'\"), ('utopia', 'n4'), ('dark', 'concept'), ('fake', 'concern'), (\"hala'\", \"'1\"), ('food', 'sanitation'), ('major', 'issues'), ('buy', 'album'), (\"what's\", 'going'), ('stop', 'using'), ('ni', 'guess'), ('name', 'n5'), ('chronic', 'pain'), ('bias', 'wrecking'), ('solo', 'album'), ('jackie', 'chan'), ('shinee', 'exo'), ('glad', 'see'), ('could', 'go'), ('promoted', 'anyway'), ('7th', 'anniversary'), ('drunk', 'driver'), ('hello', 'counselor'), ('n3', 'utopia'), ('knowing', 'brothers'), ('kpop', 'playlists'), ('nature', 'republic'), ('get', 'away'), (\"'han\", 'seo'), ('promise', 'n5'), ('without', 'taking'), ('grown', 'adult'), ('hearing', 'impairment'), (\"'ah\", 'yes'), ('ü§∑üèª', 'u200d‚ôÄÔ∏è'), ('wonho', 'shownu'), ('mass', 'shooters'), ('pretty', 'well'), ('huge', 'deal'), ('currently', 'nomination'), ('western', 'pop'), ('new', 'group'), (\"'holy\", 'moly'), ('hoe', 'anthem'), ('self', 'aware'), ('hire', 'someone'), (\"i'm\", 'hyped'), ('less', 'relevant'), ('moon', 'landing'), ('news', 'broke'), ('gave', 'chills'), ('many', 'artists'), ('ni', 'really'), ('level', 'criticism'), ('really', 'love'), ('cautiously', 'optimistic'), ('hominem', 'attacks'), (\"'re\", 'gonna'), ('started', 'stanning'), ('one', 'reasons'), ('n4', 'promise')]\nunique_top_female_bigram_tuples: [('feel', 'special'), ('pum', 'pum'), ('„Öã„Öã„Öã„Öã', '„Öã„Öã„Öã„Öã'), ('park', 'bom'), ('oh', 'girl'), ('girl', 'crush'), ('park', 'night'), ('glass', 'shoes'), ('rum', 'pum'), ('love', 'bomb'), ('weki', 'meki'), ('city', 'pop'), ('deja', 'vu'), ('electric', 'shock'), ('nu', 'abo'), ('rocket', 'punch'), ('lee', 'hi'), ('red', 'light'), ('night', 'part'), ('ice', 'cream'), ('idol', 'school'), ('heart', 'attack'), ('21', '29'), ('fly', 'high'), ('cherry', 'motion'), ('love', 'foolish'), ('uh', 'oh'), ('love', 'rumpumpum'), ('sixth', 'sense'), ('bang', 'bang'), ('russian', 'roulette'), ('pinky', 'star'), ('cherry', 'bullet'), ('hotel', 'del'), ('22century', 'girl'), ('roll', 'deep'), ('puzzle', 'moon'), ('anxiety', 'disorder'), ('studio', 'version'), ('yes', 'yes'), ('del', 'luna'), ('secret', 'garden'), ('hi', 'high'), ('twenty', 'three'), ('sweet', 'crazy'), ('silent', 'night'), ('brown', 'eyed'), ('top', 'tier'), ('hot', 'summer'), ('eh', 'eh'), ('nscroll', 'scroll'), ('scroll', 'nscroll'), ('bomb', 'n2'), (\"'she\", 'looks'), ('amp', 'nbsp'), ('girl', 'front'), ('youtube', 'channel'), ('produce', '48'), ('red', 'sun'), ('hocus', 'pocus'), ('ioi', 'reunion'), ('love', 'cherry'), ('malicious', 'comments'), ('tweaks', 'heavy'), ('female', 'idols'), ('rich', 'brian'), ('dancing', 'queen'), ('heavy', 'cloud'), ('cha', 'ta'), ('scroll', 'scroll'), ('22nd', 'century'), ('short', 'hair'), ('plastic', 'surgery'), ('get', 'loud'), ('cloud', 'rain'), ('total', 'eclipse'), ('sub', 'unit'), ('century', 'girl'), ('survival', 'shows'), ('la', 'cha'), ('tropical', 'house'), ('bubble', 'pop'), ('sexy', 'concept'), ('vie', 'en'), ('health', 'issues'), ('reve', 'festival'), ('bboom', 'bboom'), ('unpopular', 'opinion'), ('ping', 'pong'), ('red', 'flavor'), ('ah', 'choo'), ('boom', 'boom'), ('bar', 'bar'), ('dalla', 'dalla'), ('crayon', 'pop'), ('music', 'core'), ('jam', 'jam'), ('ethnic', 'hip'), ('night', 'aviation'), ('top', '10'), ('eyed', 'girls'), (\"'red\", 'velvet'), ('screen', 'time'), ('foul', 'play'), ('pink', 'tape'), ('buenos', 'aires'), ('chewing', 'gum'), ('live', 'vocals'), ('last', 'minute'), ('light', 'stick'), (\"i'm\", 'guessing'), ('olivia', 'hye'), ('kpop', 'idols'), ('bingle', 'bangle'), ('10th', 'anniversary'), ('cheng', 'xiao'), ('ddu', 'du'), ('hair', 'color'), ('evil', 'editing'), (\"'hi\", 'kyla'), ('real', 'name'), ('show', 'champion'), ('extreme', 'diets'), ('rabbit', 'hole'), (\"girl's\", 'day'), ('four', 'seasons'), ('curse', 'spider'), ('amp', 'hip'), ('lip', 'amp'), ('la', 'vie'), ('slippery', 'slope'), ('solo', 'activities'), ('sing', 'live'), ('comment', 'section'), ('interpretation', 'dreams'), ('rendezvous', '18'), ('past', 'years'), ('physical', 'album'), ('red', 'shoes'), (\"we're\", 'getting'), ('daisy', 'taeha'), ('lucky', 'strike'), ('n4', 'park'), ('peek', 'boo'), ('right', 'wing'), ('running', 'man'), ('iz', \"one's\"), ('black', 'dress'), ('highlight', 'medley'), ('en', 'rose'), ('makes', 'happy'), ('bbi', 'bbi'), ('rude', 'love'), ('cyber', 'bullying'), ('18', '6y'), ('neomu', 'neomu'), ('kim', 'lip'), ('japanese', 'releases'), ('new', 'songs'), ('breast', 'cancer'), ('dome', 'tour'), ('eung', 'eung'), ('red', \"velvet's\"), ('hateful', 'comments'), ('mid', 'tier'), ('orange', 'caramel'), ('blonde', 'hair'), ('digital', 'sales'), ('idol', 'room'), ('modern', 'times'), ('jakku', 'jakku'), ('male', 'idols'), ('comfort', 'zone'), (\"'i\", 'remember'), ('backing', 'track'), ('02', '2020'), ('new', 'music'), ('pre', 'recorded'), ('black', 'label'), ('melting', 'point'), ('singing', 'rain'), ('family', 'friends'), ('nred', 'velvet'), ('sun', '021'), ('lose', 'weight'), ('starry', 'night'), ('extreme', 'dieting'), ('ultimate', 'bias'), ('steel', 'wool'), ('crazy', 'love'), (\"'i\", 'wonder'), ('irene', 'seulgi'), ('digital', 'single'), ('every', 'group'), (\"can't\", 'help'), (\"'oh\", 'wow'), ('growing', 'groo'), ('high', 'pitched'), (\"'i\", 'know'), ('safety', 'shorts'), ('point', 'view'), ('unpretty', 'rapstar'), ('cute', 'concepts'), ('came', 'back'), ('fall', 'love'), ('caught', 'guard'), ('ending', 'scene'), ('knock', 'knock'), (\"'at\", 'least'), ('wee', 'woo'), (\"'1\", 'love'), ('united', 'states'), ('immortal', 'songs'), ('dua', 'lipa'), ('suki', 'iwasetai'), ('22', 'century'), ('good', 'day'), ('towards', 'end'), ('miss', 'ping'), ('omg', 'lovelyz'), ('magnetic', 'moon'), ('say', 'anything'), ('nat', 'least'), (\"'1\", 'park'), ('constructive', 'criticism'), ('years', 'old'), ('n3', 'park'), ('gloomy', 'clock'), ('bias', 'wrecker'), ('better', 'babe'), ('idol', 'life'), ('nizi', 'project'), ('weight', 'loss'), ('abs', 'cbn'), ('bad', 'boy'), ('shock', 'value'), ('melanie', 'fontana'), ('young', 'age'), ('age', 'gap'), ('don‚Äôt', 'understand'), ('send', 'modmail'), ('aviation', 'interpretation'), ('carly', 'rae'), (\"'pretty\", 'sure'), ('ni', 'love'), ('ending', 'page'), ('something', 'similar'), ('pushed', 'back'), ('dear', 'name'), ('holding', 'back'), (\"'rest\", 'peace'), ('part', 'three'), ('coast', 'azure'), ('ex', 'pristin'), ('gonna', 'lie'), ('ladies', 'code'), ('fc', 'rumor'), ('dealing', 'asshats'), ('mamma', 'mia'), ('good', 'thing'), ('drag', 'queens'), ('live', 'stages'), ('please', 'send'), ('purple', 'ss'), ('work', 'hard'), ('grain', 'salt'), ('shy', 'shy'), ('radio', 'star'), ('unfortunately', 'submission'), ('teen', 'crush'), ('bad', 'thing'), ('interesting', 'see'), ('ice', 'ice'), ('ha', 'tfelt'), ('purple', 'kiss'), ('exit', 'nodes'), ('keke', 'palmer'), ('physical', 'albums'), ('lip', 'hip'), ('cream', 'cake'), ('hey', 'hey'), ('saint', 'laurent'), ('green', 'apple'), ('really', 'hard'), ('looks', 'good'), ('wrote', 'lyrics'), (\"i'm\", 'still'), ('live', 'singing'), ('new', 'gg'), ('anyone', 'know'), ('favorite', 'dreamcatcher'), (\"there's\", 'reason'), ('nlooking', 'forward'), ('never', 'thought'), ('delete', 'malformed'), ('high', 'horse'), ('plot', 'twist'), ('release', 'single'), ('last', 'night'), ('full', 'length'), ('end', 'year'), ('idol', 'producer'), ('pristin', 'girls'), ('01', '2020'), ('npark', 'bom'), ('produce', 'series'), ('bon', 'bon'), ('ni', 'know'), ('beautiful', 'stranger'), ('doni', 'coni'), ('investigate', 'foul'), (\"let's\", 'go'), ('pink', 'blusher'), ('cherry', 'blossoms'), (\"there's\", 'nothing'), ('town', 'hall'), ('singing', 'live'), ('highly', 'recommend'), ('looks', 'gorgeous'), ('force', 'reckoned'), ('lee', 'hyeyoung'), ('favorite', 'song'), ('friends', 'family'), ('sweet', 'witches'), (\"'jesus\", 'christ'), ('favourite', 'song'), ('gaon', 'weekly'), ('cute', 'concept'), ('bomb', 'n3'), ('cf', 'deals'), (\"i'm\", 'hoping'), ('thank', 'much'), ('noh', 'girl'), ('du', 'ddu'), ('n3', 'red'), ('rest', 'peace'), ('bloom', 'iz'), ('rae', 'jepsen'), ('conspiracy', 'theories'), ('small', 'company'), ('wind', 'flower'), ('hidden', 'member'), ('public', 'figures'), ('brand', 'new'), ('non', 'existent'), ('could', 'potentially'), ('paper', 'heart'), ('pretty', 'obvious'), ('league', 'legends'), ('comment', 'history'), ('fake', 'fake'), ('need', 'stop'), ('three', 'n2'), ('dal', 'shabet'), ('katy', 'perry'), ('per', 'year'), ('really', 'nice'), ('pristin', 'members'), ('highly', 'doubt'), ('thank', 'submitting'), ('world', 'domination'), ('spill', 'tea'), ('seemed', 'like'), ('asshats', 'online'), ('color', 'scheme'), ('submission', 'removed'), (\"we're\", 'talking'), ('britney', 'spears'), ('almost', 'always'), ('people', 'say'), ('dance', 'moves'), ('mental', 'illnesses'), ('fake', 'true'), ('black', 'pink'), ('get', 'downvoted'), (\"girls'\", 'generation'), ('irene', 'amp'), ('masked', 'singer'), ('ni', \"'t\"), ('summer', 'bop'), ('several', 'times'), ('absolutely', 'gorgeous'), ('happy', 'happy'), ('everybody', 'secrets'), (\"i've\", 'waiting'), ('jump', 'conclusions'), ('jump', 'secs'), ('giving', 'us'), ('streaming', 'services'), ('became', 'fan'), (\"'t\", 'really'), ('many', 'ways'), ('nfor', 'example'), ('5th', 'member'), (\"'i\", 'really'), ('quite', 'bit'), ('want', 'see'), ('dancing', \"queen'\"), ('read', 'article'), ('male', 'female'), ('gonna', 'get'), ('wardrobe', 'malfunction'), ('tongue', 'cheek'), ('three', 'times'), ('disordered', 'eating'), ('whatever', 'reason'), ('loved', 'ones'), ('original', 'song'), ('automoderator', 'bot'), ('variety', 'appearances'), ('black', 'hole'), (\"'hi\", 'min'), ('would', 'love'), (\"love'\", \"'1\"), ('honestly', 'think'), ('n2', 'love'), ('pretty', 'cool'), ('full', 'version'), ('start', 'finish'), ('weekly', 'idol'), ('korea', 'japan'), ('jeff', 'benjamin'), ('phone', 'number'), ('never', 'really'), ('since', '2016'), ('vote', 'manipulation'), ('19', 'year'), ('i‚Äôve', 'ever'), ('moving', 'forward'), ('rap', 'verse'), ('mental', 'healthcare'), ('violation', 'reports'), (\"'i\", 'wish'), ('star', 'wars'), (\"here's\", 'hoping'), ('n2', 'park'), ('twinkle', 'twinkle'), ('ayayaya', 'curious'), ('locked', 'questions'), ('sexy', 'concepts'), ('feel', 'free'), ('internet', 'security'), ('favorite', 'songs'), ('gave', 'us'), ('started', 'listening'), ('pure', 'speculation'), ('dance', 'covers'), ('personal', 'preference'), ('english', 'subs'), ('ddu', 'ddu'), ('secs', 'earlier'), (\"'oh\", 'yeah'), ('creative', 'director'), (\"'does\", 'anyone'), ('part', \"one'\"), ('next', 'month'), ('000', 'points'), ('five', 'years'), ('keys', 'n3'), ('mr', 'boogie'), ('kim', 'gura'), ('january', '7th'), ('stage', 'name'), ('n2', 'keys'), ('even', 'worse'), ('singing', 'dancing'), ('seeking', 'attention'), ('passed', 'away'), (\"'what\", 'fuck'), ('bing', 'bing'), ('radio', 'silence'), ('kpop', 'questions'), ('perfectly', 'fine'), ('law', 'enforcement'), ('bim', 'bam'), ('sounds', 'amazing'), ('sounded', 'like'), ('acoustic', 'ver'), ('gustas', 'tu'), ('uncanny', 'valley'), ('code', 'suggestions'), ('love', 'letter'), ('mbc', 'gayo'), ('place', 'heart'), ('foreign', 'fans'), ('everyone', 'knows'), ('yt', 'channel'), ('fifth', 'season'), ('seulgi', 'irene'), ('bam', 'bum'), ('live', 'stage'), ('70s', '80s'), ('cak', 'naver'), ('whatever', 'want'), ('10', 'minutes'), ('sang', 'live'), ('modmail', 'bot'), ('iu', 'taeyeon'), ('indefinite', 'hiatus'), (\"aoa's\", 'performance'), ('sailor', 'moon'), ('excited', 'comeback'), ('leez', 'ollounder'), ('god', 'damn'), ('different', 'concepts'), (\"queen'\", \"'1\"), ('southeast', 'asia'), ('negative', 'comments'), ('cj', 'enm'), ('teaser', 'images'), ('real', 'names'), ('white', 'knight'), ('shoes', 'n5'), ('past', 'year'), ('couple', 'days'), ('next', 'door'), ('efron', 'tisdale'), (\"'can\", 'someone'), ('mental', 'state'), (\"i'd\", 'love'), ('blood', 'sweat'), ('get', 'wrong'), ('carefully', 'determine'), ('nat', 'end'), ('pit', 'pet'), ('length', \"url's\"), ('female', 'idol'), ('airplane', 'n2'), ('red', 'velvet‚Äôs'), ('remember', 'correctly'), ('gregorian', 'calendar'), ('could', 'possibly'), (\"ladies'\", 'code'), ('20', 'years'), (\"'1\", 'airplane'), ('la', 'rouge'), ('fake', 'amp'), ('nrest', 'peace'), (\"'thanks\", 'added'), ('meg', 'dia'), ('sounds', 'great'), ('concept', 'change'), ('top', 'gg'), (\"can't\", 'get'), ('japanese', 'version'), (\"'i\", 'guess'), ('next', 'level'), (\"'sounds\", 'like'), (\"'what\", 'happened'), (\"i'm\", 'fan'), ('lil', 'touch'), ('ip', 'address'), ('concentration', 'camps'), ('ntl', 'dr'), (\"'a\", 'lot'), ('million', 'views'), ('gotta', 'go'), (\"'for\", 'real'), (\"url's\", 'bot'), ('catch', 'break'), ('ni', 'also'), ('mine', 'coast'), ('doo', 'doo'), (\"'they\", 'look'), ('members', 'left'), ('n7', 'heart'), ('really', 'really'), ('thread', 'locked'), ('kill', 'love'), ('main', 'rapper'), ('beauty', 'standards'), ('practice', 'videos'), ('news', 'sites'), ('paved', 'way'), ('charli', 'taft')]\n"
    }
   ],
   "source": [
    "top_female_bigram_tuples = top_ngrams(female_giant_comment_string, top_n=1000, ngram=2)\n",
    "top_male_bigram_tuples = top_ngrams(male_giant_comment_string, top_n=1000, ngram=2)\n",
    "\n",
    "unique_top_male_bigram_tuples = []\n",
    "for t in top_male_bigram_tuples:\n",
    "    if t not in top_female_bigram_tuples:\n",
    "        unique_top_male_bigram_tuples.append(t)\n",
    "print('unique_top_male_bigram_tuples: {}'.format(unique_top_male_bigram_tuples))\n",
    "\n",
    "unique_top_female_bigram_tuples = []\n",
    "for t in top_female_bigram_tuples:\n",
    "    if t not in top_male_bigram_tuples:\n",
    "        unique_top_female_bigram_tuples.append(t)\n",
    "print('unique_top_female_bigram_tuples: {}'.format(unique_top_female_bigram_tuples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "unique_top_male_bigram_tuples: [('wtf', 'wtf'), ('pirate', 'king'), ('hala', 'hala'), ('nct', '127'), ('saudi', 'arabia'), ('harry', 'potter'), ('bear', 'consequences'), ('say', 'name'), ('roller', 'coaster'), ('run', 'away'), ('stand', 'rain'), ('wanna', 'one'), ('fairy', 'shampoo'), ('yang', 'hyun'), ('pre', 'orders'), ('side', 'effects'), ('jay', 'park'), ('golden', 'phone'), ('cherry', 'bomb'), ('seo', 'hee'), ('da', 'eun'), ('consequences', 'apply'), ('reiterating', 'jackson'), ('butterfly', 'wings'), ('choose', 'bear'), ('magic', 'island'), ('shangri', 'la'), ('new', 'rules'), ('safety', 'video'), ('dazzling', 'light'), ('sexual', 'assault'), ('jackson', 'choose'), ('maze', 'mirror'), ('sex', 'workers'), ('tl', 'dr'), ('radio', 'play'), ('angel', 'devil'), ('black', 'culture'), ('exo', 'ls'), ('han', 'seo'), ('korean', 'air'), ('chow', 'yun'), ('yun', 'fat'), ('apply', 'different'), ('golden', 'child'), ('reading', 'comprehension'), ('sweet', 'chaos'), ('drunk', 'driving'), ('lower', 'register'), ('politically', 'tangled'), ('ten', 'lucas'), ('monthly', 'listeners'), ('miley', 'cyrus'), ('different', 'logic'), ('noodle', 'soup'), ('road', 'kingdom'), ('us', 'market'), ('super', 'clap'), ('fender', 'bender'), ('n10', \"stay'\"), ('plastic', 'pants'), ('tik', 'tok'), ('political', 'inclination'), ('riyadh', 'season'), ('snap', 'shoot'), ('capitol', 'records'), ('chicken', 'noodle'), ('politically', 'inclined'), ('super', 'car'), ('highway', 'heaven'), ('soo', 'man'), ('ding', 'dong'), ('burning', 'molka'), ('criticising', 'fully'), ('nick', 'fury'), ('opportunities', 'nwhich'), ('chinese', 'government'), (\"stay'\", \"'1\"), ('ass', 'criticising'), ('back', 'home'), ('chris', 'brown'), ('rightfully', 'bear'), ('han', 'seohee'), ('smoking', 'weed'), ('flowing', 'wind'), ('john', 'cena'), ('un', 'village'), ('rest', 'album'), ('jumping', 'popping'), ('third', 'party'), ('monsta', \"x's\"), ('criteria', 'disappointed'), ('press', 'conference'), ('without', 'consent'), ('military', 'service'), ('brr', 'brr'), ('james', 'corden'), ('middle', 'east'), ('destroyed', 'damaged'), ('condoning', 'address'), ('happy', 'anniversary'), ('boy', 'band'), ('queer', 'baiting'), ('jung', 'da'), ('logic', 'people'), ('las', 'vegas'), ('nicki', 'minaj'), ('hostage', 'confession'), ('actions', 'rightfully'), ('inclination', 'might'), ('2017', '18'), ('destroying', 'person‚Äôs'), ('siding', 'stalkers'), ('english', 'speaker'), ('stand', 'favour'), ('address', 'seperate'), ('thermal', 'imaging'), ('nwhich', 'jackson'), (\"'1\", 'hala'), ('tangled', \"can't\"), ('entertainment', 'industries'), ('like', 'butterfly'), ('lucas', 'ten'), ('common', 'sense'), ('survive', 'without'), ('smoked', 'weed'), ('yuqi', 'nct'), ('tax', 'evasion'), ('suck', 'ccp'), ('middle', 'school'), ('nct', 'wayv'), (\"'1\", 'promise'), ('mickey', 'mouse'), ('el', 'dorado'), ('gel', 'twists'), ('situation', 'reiterating'), ('level', 'critcism'), ('lo', 'siento'), ('fully', 'understanding'), ('illusion', 'n9'), (\"can't\", 'stand'), ('n8', 'illusion'), ('leave', 'alone'), ('turn', 'back'), ('exo', 'sc'), ('jang', 'sungkyu'), ('seo', 'taiji'), ('dream', 'chapter'), ('drug', 'use'), ('simon', 'cowell'), ('lying', 'omission'), ('black', 'atinys'), ('view', 'count'), ('country', 'politically'), ('dance', 'practices'), ('romeo', 'juliet'), ('wave', 'n4'), ('offensive', 'pro'), ('industries', 'china'), ('nyeah', 'whatever'), ('concept', 'trailer'), ('pre', 'ordered'), ('promise', 'n2'), ('damaged', 'twice'), ('everyone', 'criteria'), ('second', 'verse'), ('ccp', 'weibo'), ('ni', 'feel'), ('n3', 'wave'), ('got', 'married'), ('electric', 'guitar'), ('juvenile', 'detention'), ('seperate', 'rather'), ('physical', 'sales'), ('china', 'politically'), ('ngiving', 'level'), ('nap', 'star'), ('born', 'china'), ('inclined', 'take'), ('deep', 'breath'), ('getting', 'downvoted'), ('role', 'models'), ('critcism', 'nothing'), ('zero', 'lines'), ('consequences', 'half'), ('termination', 'fees'), ('half', 'ass'), ('dog', 'meat'), ('posted', 'siding'), ('understanding', 'situation'), ('line', 'born'), ('issue', 'ngiving'), ('black', 'suit'), ('take', 'advantage'), (\"can't\", 'survive'), ('city', 'lights'), ('urban', 'dictionary'), ('double', 'knot'), ('love', 'shot'), ('please', 'let'), ('rather', 'ironic'), ('thanksgiving', 'parade'), ('proven', 'guilty'), (\"'i\", 'can‚Äôt'), ('sexual', 'harassment'), ('don‚Äôt', 'want'), ('career', '2017'), ('hala', 'n2'), ('view', 'counts'), ('jackson', 'shitty'), ('new', 'world'), ('pearl', 'aqua'), ('street', 'team'), ('digital', 'downloads'), (\"we've\", 'seen'), ('rookie', 'award'), ('confession', 'apology'), ('american', 'market'), ('whatever', 'political'), ('hala', 'n6'), ('wave', 'n7'), ('posting', 'address'), ('hk', 'pride'), ('please', 'visit'), ('network', 'love'), ('nominated', 'rookie'), ('soompi', 'article'), ('person‚Äôs', 'career'), ('rap', 'line'), ('somewhere', 'else'), ('nsure', 'however'), ('n6', 'wave'), ('air', 'safety'), ('n5', 'hala'), ('weibo', 'held'), ('general', 'feedback'), ('ironic', 'issue'), ('pro', 'china'), ('couple', 'times'), ('umbrella', 'movement'), ('rap', 'heavy'), ('sexually', 'harassed'), ('americans', 'western'), ('tummy', 'fat'), ('many', 'years'), ('excuse', 'basically'), ('held', 'flag'), ('owes', 'money'), ('award', 'show'), ('mouse', 'club'), ('baby', 'stop'), ('charlie', 'puth'), ('musical', 'direction'), ('leaning', 'towards'), ('backstreet', 'boys'), ('casual', 'listener'), ('middle', 'eastern'), ('car', 'accident'), ('every', 'member'), ('ed', 'sheeran'), ('flower', 'shower'), ('pop', 'groups'), ('cancel', 'culture'), ('sm', 'capitol'), ('korean', 'fans'), ('cookie', 'cutter'), ('lana', 'del'), ('wayv', 'seventeen'), ('1b', 'views'), ('judge', 'everyone'), ('huening', 'kai'), ('change', 'fact'), ('leave', 'monster'), ('netz', 'known'), ('bot', 'nthis'), ('pop', 'music'), ('morse', 'code'), ('open', 'minded'), ('seventeen', 'line'), ('old', 'school'), ('role', 'model'), ('cat', 'amp'), ('grand', 'scheme'), ('career', 'nsure'), ('meow', 'meow'), ('simon', 'says'), (\"they're\", 'still'), ('nothing', 'else'), ('get', 'opportunities'), ('disappointed', 'views'), ('05', '49'), ('ni', 'reiterating'), ('500', '000'), ('absolutely', 'love'), ('good', 'idea'), ('cash', 'grab'), ('point', 'condoning'), ('united', 'version'), ('china', 'excuse'), ('blue', 'orangeade'), ('count', 'towards'), ('taking', 'stand'), ('late', 'night'), ('monkey', 'museum'), ('entirely', 'valid'), ('white', 'people'), ('nu', \"'est\"), ('put', 'together'), ('taemin', 'kai'), ('like', 'said'), ('renjun', 'chenle'), ('western', 'countries'), ('asian', 'countries'), ('200k', '300k'), ('jong', 'hyun'), ('name', 'n2'), ('intense', 'criticism'), ('least', 'upvotes'), ('country', 'promoting'), ('promoting', 'country'), ('etc', 'etc'), ('slap', 'face'), ('lgbt', 'community'), (\"'m\", 'saying'), ('non', 'fans'), ('nalso', 'tzuyu'), ('views', 'actions'), ('early', '2000s'), ('english', 'lyrics'), ('disney', 'nick'), ('floating', 'around'), ('deep', 'love'), ('oh', 'wow'), ('gel', 'twirls'), ('favour', 'get'), ('whole', 'album'), ('stop', 'talking'), ('chinese', 'flag'), ('chef', 'kiss'), ('stand', 'whatever'), ('1st', 'day'), ('fresh', 'air'), ('n10', \"utopia'\"), ('funk', 'styles'), ('entertainment', 'companies'), (\"utopia'\", \"'1\"), ('social', 'distancing'), ('relevant', 'excuse'), ('really', 'excited'), ('top', 'head'), ('making', 'money'), ('public', 'opinion'), ('trying', 'say'), ('michael', 'jackson'), ('hyyh', 'pt'), ('going', 'happen'), ('cj', 'amp'), ('bad', 'alive'), ('top', 'weekly'), ('held', 'major'), ('million', 'seller'), ('camera', 'work'), ('taxi', 'driver'), ('lee', 'jong'), ('lot', 'money'), ('don‚Äôt', 'see'), ('jackson', 'start'), ('ring', 'ding'), ('black', 'swan'), ('rookie', 'groups'), ('korean', 'artist'), ('debut', 'album'), ('sorry', 'sorry'), ('avant', 'garde'), ('bossa', 'nova'), ('goo', 'hara'), ('jinhwan', 'junhoe'), ('trying', 'get'), ('7th', 'sense'), ('release', 'date'), ('like', 'yuqi'), ('n4', 'utopia'), ('baekhyun', 'kai'), (\"'re\", 'talking'), ('native', 'speaker'), ('one', 'person'), ('song', 'sounds'), ('wannabe', 'without'), ('stalkers', 'nthe'), ('n10', \"treasure'\"), ('western', 'media'), ('avengers', 'kpop'), ('see', 'perform'), ('civil', 'rights'), ('criticism', 'entirely'), ('china', 'ultimately'), ('25', 'least'), ('aesthetically', 'pleasing'), ('taeyong', 'mark'), ('hk', 'taiwan'), ('address', 'posted'), ('treasure', 'n8'), (\"poppin'\", 'star'), ('saying', 'suck'), ('music', 'auto'), ('status', 'quo'), ('left', 'field'), ('desire', 'n8'), ('keep', 'mind'), ('n5', 'pirate'), ('guilt', 'tripping'), (\"macy's\", 'thanksgiving'), ('n7', 'treasure'), ('billboard', '200'), ('mentalities', 'experiences'), ('breath', 'fresh'), ('n7', 'desire'), ('media', 'play'), ('ceo', 'yang'), ('cancellation', 'fee'), ('real', 'estate'), ('promise', 'n4'), ('criticism', 'jackson'), ('idols', 'promoting'), ('49', '20z'), ('duluth', 'ga'), ('hideo', 'kojima'), ('statute', 'limitations'), ('since', '2014'), ('want', 'support'), ('innocent', 'proven'), ('performance', 'video'), ('go', 'ahead'), ('global', 'shop'), ('smart', 'move'), ('full', 'offensive'), ('idol', 'industry'), ('deleted', 'deleted'), ('flag', 'whatever'), ('core', 'fandom'), ('known', 'intense'), ('chat', 'rooms'), ('12am', 'kst'), ('jingle', 'ball'), ('speaks', 'volumes'), ('one', 'biggest'), ('three', 'months'), ('gotta', 'say'), ('n3', 'promise'), ('fandom', 'name'), ('last', 'two'), ('baekhyun', 'taemin'), ('monsta', 'x‚Äôs'), ('09', '22z'), ('iron', 'maiden'), ('sore', 'thumb'), ('someone', 'explain'), ('phase', '9th'), ('teaser', 'pics'), ('beginning', 'end'), ('drug', 'dealer'), ('monster', 'alive'), ('terminate', 'contract'), (\"what's\", 'wrong'), ('political', 'climate'), ('keep', 'going'), ('sun', 'scandal'), ('fight', 'death'), ('member', 'group'), ('gd', 'taeyang'), ('del', 'rey'), ('name', 'n3'), ('11', 'years'), ('light', 'mist'), ('least', 'favorite'), ('moonlight', 'sonata'), ('start', 'chinese'), (\"'t\", 'hostage'), ('end', 'stick'), ('middle', 'aged'), ('even', 'better'), (\"'t\", 'want'), ('high', 'budget'), ('opium', 'war'), ('war', 'bonnets'), ('agent', 'orange'), ('point', 'destroying'), ('cake', 'day'), ('Õú ñ', 'Õ°¬∞'), ('Õ°¬∞', 'Õú ñ'), ('taste', 'mouth'), ('take', 'stand'), ('wear', 'dreads'), ('hormone', 'therapy'), ('000', 'copies'), ('victim', 'complex'), ('king', 'n6'), ('poppin', 'star'), ('utopia', 'n5'), ('drug', 'tests'), ('another', 'group'), ('chemical', 'romance'), ('easter', 'eggs'), ('thing', 'americans'), ('excuse', 'actions'), ('chinese', 'solo'), ('aju', 'nice'), ('going', 'destroyed'), ('n8', 'pirate'), ('joon', 'young'), ('marching', 'band'), ('quantum', 'leap'), ('butt', 'biting'), ('low', 'budget'), ('n10', \"aurora'\"), ('utopia', 'n4'), ('dark', 'concept'), ('fake', 'concern'), (\"hala'\", \"'1\"), ('food', 'sanitation'), ('major', 'issues'), ('buy', 'album'), (\"what's\", 'going'), ('stop', 'using'), ('ni', 'guess'), ('name', 'n5'), ('chronic', 'pain'), ('bias', 'wrecking'), ('solo', 'album'), ('jackie', 'chan'), ('shinee', 'exo'), ('glad', 'see'), ('could', 'go'), ('promoted', 'anyway'), ('7th', 'anniversary'), ('drunk', 'driver'), ('hello', 'counselor'), ('n3', 'utopia'), ('knowing', 'brothers'), ('kpop', 'playlists'), ('nature', 'republic'), ('get', 'away'), (\"'han\", 'seo'), ('promise', 'n5'), ('without', 'taking'), ('grown', 'adult'), ('hearing', 'impairment'), (\"'ah\", 'yes'), ('ü§∑üèª', 'u200d‚ôÄÔ∏è'), ('wonho', 'shownu'), ('mass', 'shooters'), ('pretty', 'well'), ('huge', 'deal'), ('currently', 'nomination'), ('western', 'pop'), ('new', 'group'), (\"'holy\", 'moly'), ('hoe', 'anthem'), ('self', 'aware'), ('hire', 'someone'), (\"i'm\", 'hyped'), ('less', 'relevant'), ('moon', 'landing'), ('news', 'broke'), ('gave', 'chills'), ('many', 'artists'), ('ni', 'really'), ('level', 'criticism'), ('really', 'love'), ('cautiously', 'optimistic'), ('hominem', 'attacks'), (\"'re\", 'gonna'), ('started', 'stanning'), ('one', 'reasons'), ('n4', 'promise')]\n"
    }
   ],
   "source": [
    "print('unique_top_male_bigram_tuples: {}'.format(unique_top_male_bigram_tuples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set_top_male_bigram_tuples = set(top_male_bigram_tuples)\n",
    "# set_top_female_bigram_tuples = set(top_female_bigram_tuples)\n",
    "# print(set_top_male_bigram_tuples - set_top_female_bigram_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{('24', 'hours'), ('four', 'seasons'), ('really', 'like'), ('ice', 'cream'), ('ah', 'choo'), ('new', 'music'), ('la', 'vie'), ('solo', 'activities'), (\"'it\", \"'s\"), ('peek', 'boo'), ('couple', 'years'), ('main', 'vocal'), ('orange', 'caramel'), (\"i'd\", 'say'), ('comfort', 'zone'), ('singing', 'rain'), ('dome', 'tour'), ('02', '2020'), ('hi', 'high'), ('red', 'sun'), ('hocus', 'pocus'), ('black', 'label'), ('reve', 'festival'), ('roll', 'deep'), (\"'i\", 'thought'), ('steel', 'wool'), ('united', 'states'), (\"we're\", 'getting'), ('weki', 'meki'), ('city', 'pop'), ('evil', 'editing'), ('dalla', 'dalla'), ('lil', 'nas'), ('digital', 'single'), ('lucky', 'strike'), ('light', 'stick'), ('dancing', 'queen'), ('melting', 'point'), ('en', 'rose'), ('looked', 'like'), ('uh', 'oh'), ('nowhere', 'near'), (\"'hi\", 'kyla'), ('real', 'name'), ('nice', 'see'), ('extreme', 'diets'), ('almost', 'every'), ('live', 'vocals'), ('ping', 'pong'), ('oh', 'girl'), ('pum', 'pum'), ('bboom', 'bboom'), ('boom', 'boom'), ('ioi', 'reunion'), ('rich', 'brian'), ('love', 'bomb'), ('crazy', 'love'), ('freedom', 'speech'), ('anytime', 'soon'), ('21', '29'), ('eung', 'eung'), ('short', 'hair'), ('girl', 'crush'), ('fly', 'high'), ('jam', 'jam'), ('electric', 'shock'), ('last', 'week'), ('new', 'songs'), ('cute', 'concepts'), ('chewing', 'gum'), (\"i'm\", 'sorry'), ('anxiety', 'disorder'), ('earlier', 'year'), ('japanese', 'releases'), ('crayon', 'pop'), ('nred', 'velvet'), ('running', 'man'), ('sun', '021'), ('free', 'speech'), ('twenty', 'three'), ('bang', 'bang'), ('holy', 'crap'), ('sexy', 'concept'), ('hateful', 'comments'), ('live', 'performances'), ('lip', 'syncing'), ('blonde', 'hair'), ('dating', 'scandal'), ('high', 'pitched'), ('plastic', 'surgery'), ('let', \"'s\"), ('youtube', 'channel'), (\"'looks\", 'like'), (\"'1\", 'love'), ('every', 'group'), ('new', 'york'), ('eh', 'eh'), ('la', 'cha'), ('physical', 'album'), ('last', 'minute'), ('cha', 'ta'), ('malicious', 'comments'), (\"'she\", 'looks'), ('youtube', 'views'), ('scroll', 'nscroll'), ('immortal', 'songs'), ('ending', 'scene'), ('foul', 'play'), (\"'oh\", 'wow'), ('jesus', 'christ'), ('pink', 'tape'), ('billie', 'eilish'), (\"i'm\", 'guessing'), ('jakku', 'jakku'), ('breast', 'cancer'), ('girl', 'front'), ('show', 'champion'), ('sing', 'live'), ('cloud', 'rain'), ('daisy', 'taeha'), ('english', 'speaking'), ('22nd', 'century'), ('heart', 'attack'), ('bomb', 'n2'), ('chung', 'ha'), ('reality', 'show'), ('red', 'shoes'), ('lee', 'hi'), ('east', 'asian'), ('get', 'loud'), ('park', 'night'), ('mid', 'tier'), ('umpah', 'umpah'), ('right', 'wing'), ('love', 'foolish'), (\"'at\", 'least'), ('3rd', 'gen'), ('nu', 'abo'), ('long', 'term'), ('highlight', 'medley'), ('secret', 'garden'), ('18', '6y'), ('makes', 'feel'), ('never', 'heard'), ('sixth', 'sense'), ('first', 'win'), ('century', 'girl'), ('studio', 'version'), ('female', 'idols'), ('amp', 'nbsp'), ('comment', 'section'), ('would', 'say'), ('bingle', 'bangle'), ('backing', 'track'), ('puzzle', 'moon'), ('interpretation', 'dreams'), ('ever', 'since'), ('ever', 'heard'), ('starry', 'night'), ('hot', 'summer'), ('top', 'tier'), ('amp', 'hip'), (\"'red\", 'velvet'), ('legal', 'action'), ('sweet', 'crazy'), ('tropical', 'house'), ('good', 'luck'), ('unpretty', 'rapstar'), ('hate', 'comments'), ('n4', 'park'), ('vie', 'en'), ('top', '10'), ('night', 'part'), ('curse', 'spider'), ('around', 'world'), ('night', 'aviation'), ('hotel', 'del'), ('survival', 'shows'), ('screen', 'time'), ('pre', 'recorded'), ('buenos', 'aires'), ('„Öã„Öã„Öã„Öã', '„Öã„Öã„Öã„Öã'), ('wee', 'woo'), ('growing', 'groo'), ('ethnic', 'hip'), ('lip', 'amp'), ('pre', 'release'), ('kpop', 'idols'), (\"'i\", 'know'), ('point', 'view'), ('last', 'time'), ('black', 'dress'), ('family', 'friends'), ('music', 'bank'), ('rendezvous', '18'), ('rude', 'love'), ('wonder', 'girls'), ('silent', 'night'), ('knock', 'knock'), ('22century', 'girl'), ('glass', 'shoes'), ('past', 'years'), ('unpopular', 'opinion'), ('del', 'luna'), (\"'i\", 'remember'), ('caught', 'guard'), ('bar', 'bar'), ('ultimate', 'bias'), ('red', 'light'), ('stuck', 'head'), ('red', \"velvet's\"), ('heavy', 'cloud'), ('lip', 'sync'), ('irene', 'seulgi'), ('iz', \"one's\"), ('rocket', 'punch'), ('makes', 'happy'), ('neomu', 'neomu'), ('rum', 'pum'), ('really', 'cool'), ('deja', 'vu'), ('safety', 'shorts'), ('rabbit', 'hole'), ('weeks', 'ago'), ('cherry', 'bullet'), ('total', 'eclipse'), ('idol', 'room'), ('modern', 'times'), ('brown', 'eyed'), ('blah', 'blah'), ('park', 'bom'), ('vote', 'rigging'), ('feel', 'special'), ('two', 'years'), ('love', 'cherry'), ('lose', 'weight'), ('bubble', 'pop'), ('10th', 'anniversary'), ('solo', 'artist'), ('red', 'flavor'), ('russian', 'roulette'), ('music', 'core'), ('automatically', 'please'), ('scroll', 'scroll'), ('pinky', 'star'), ('olivia', 'hye'), ('yes', 'yes'), ('kim', 'lip'), ('cyber', 'bullying'), ('ddu', 'du'), ('slippery', 'slope'), ('cheng', 'xiao'), ('fall', 'love'), ('hair', 'color'), (\"'i\", 'wonder'), ('cherry', 'motion'), ('digital', 'sales'), ('produce', '48'), (\"can't\", 'help'), ('tweaks', 'heavy'), ('bbi', 'bbi'), ('idol', 'school'), ('male', 'idols'), ('along', 'lines'), ('personally', 'think'), ('extreme', 'dieting'), ('sub', 'unit'), ('nscroll', 'scroll'), ('came', 'back'), ('love', 'rumpumpum'), (\"girl's\", 'day'), ('next', 'comeback'), ('health', 'issues'), ('eyed', 'girls')}\n"
    }
   ],
   "source": [
    "print(set_top_female_bigram_tuples - set_top_male_bigram_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[('red', 'velvet', \"'s\"), ('red', 'velvet', 'side'), ('red', 'velvet', 'irene'), ('gt', 'red', 'velvet'), ('red', 'velvet', 'umpah'), ('red', 'velvet', 'dance'), ('red', 'velvet', 'psycho'), ('red', 'velvet', 'red'), ('congrats', 'red', 'velvet'), ('velvet', 'red', 'velvet'), ('twice', 'red', 'velvet'), ('red', 'velvet', 'n2nd'), ('14th', 'red', 'velvet'), ('pig', 'red', 'velvet'), ('dismiss', 'red', 'velvet'), ('perfect', 'red', 'velvet'), ('called', 'red', 'velvet'), ('red', 'velvet', 'apink'), ('red', 'velvet', 'blackpink'), ('red', 'velvet', 'appeared'), ('red', 'velvet', 'flop'), ('except', 'red', 'velvet'), ('bile', 'red', 'velvet'), ('grats', 'red', 'velvet'), ('meaner', 'red', 'velvet'), (\"mode'\", 'red', 'velvet'), ('red', 'velvet', 'constaantly'), ('red', 'velvet', 'Î†àÎìúÎ≤®Î≤≥'), ('spontaneously', 'red', 'velvet'), ('umpag', 'red', 'velvet'), (\"unpopular'\", 'red', 'velvet'), ('red', 'velvet', 'seulgi'), ('experimental', 'red', 'velvet'), ('red', 'velvet', 'russian'), ('red', 'velvet', '11'), ('mamamoo', 'red', 'velvet'), ('want', 'red', 'velvet'), ('red', 'velvet', 'title'), ('bridge', 'red', 'velvet'), ('red', 'velvet', 'twice'), ('red', 'velvet', 'fans'), ('reminded', 'red', 'velvet'), ('red', 'velvet', 'nexo‚Äôs'), ('gabriel', 'red', 'velvet'), ('longing', 'red', 'velvet'), ('moods', 'red', 'velvet'), ('tot', 'red', 'velvet'), ('unannounced', 'red', 'velvet'), ('red', 'velvet', 'songs'), ('casual', 'red', 'velvet')]\n"
    }
   ],
   "source": [
    "print(top_ngrams(female_giant_comment_string, top_n=50, ngram=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[('hip', 'hop'), ('title', 'track'), ('feel', 'like'), (\"can't\", 'wait'), ('wtf', 'wtf'), ('stray', 'kids'), ('pirate', 'king'), ('super', 'junior'), ('gt', 'gt'), ('makes', 'sense'), ('looking', 'forward'), ('cultural', 'appropriation'), ('amp', 'x200b'), ('mental', 'health'), ('years', 'ago'), ('hala', 'hala'), (\"i'm\", 'sure'), ('burning', 'sun'), ('sounds', 'like'), ('hong', 'kong'), ('looks', 'like'), ('social', 'media'), ('title', 'tracks'), ('seems', 'like'), ('feels', 'like'), ('pretty', 'much'), ('last', 'year'), ('nct', '127'), ('even', 'though'), ('black', 'people'), ('big', 'bang'), ('saudi', 'arabia'), ('come', 'back'), ('harry', 'potter'), (\"i've\", 'seen'), (\"i'm\", 'glad'), ('bear', 'consequences'), ('wait', 'see'), ('big', 'deal'), ('holy', 'shit'), ('general', 'public'), ('lt', \"3'\"), ('every', 'single'), ('say', 'name'), ('roller', 'coaster'), ('long', 'time'), ('first', 'place'), ('run', 'away'), ('music', 'shows'), ('kang', 'daniel')]\n"
    }
   ],
   "source": [
    "print(top_ngrams(male_giant_comment_string, top_n=100, ngram=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[('wtf', 'wtf', 'wtf'), ('hip', 'hop', 'rap'), ('hip', 'hop', 'trap'), ('hip', 'hop', 'funk'), ('hip', 'hop', 'culture'), ('lyrical', 'hip', 'hop'), ('hip', 'hop', 'rnb'), ('classic', 'hip', 'hop'), ('hip', 'hop', 'style'), ('assimilated', 'hip', 'hop'), ('denounce', 'hip', 'hop'), ('elevating', 'hip', 'hop'), ('hip', 'hop', \"dads'\"), ('hip', 'hop', 'impoverished'), ('mirrored', 'hip', 'hop'), ('ndescribing', 'hip', 'hop'), ('rigidity', 'hip', 'hop'), ('rigidnessin', 'hip', 'hop'), ('hip', 'hop', 'banger'), (\"'s\", 'hip', 'hop'), ('hip', 'hop', 'edm'), ('hip', 'hop', 'concepts'), ('flourished', 'hip', 'hop'), ('hills', 'hip', 'hop'), ('hip', 'hop', 'flourished'), ('hip', 'hop', 'reggae'), ('hip', 'hop', 'shorthand'), ('lmfaooooo', 'hip', 'hop'), ('hip', 'hop', 'definitely'), ('hip', 'hop', 'pop'), ('hip', 'hop', 'nhere‚Äôs'), ('hip', 'hop', 'righteous'), ('hip', 'hop', 'skool'), ('hip', 'hop', 'beat'), ('hoping', 'hip', 'hop'), ('hip', 'hop', 'beyonc√©'), ('hip', 'hop', 'superstar'), ('garde', 'hip', 'hop'), ('stolen', 'hip', 'hop'), ('freaky', 'hip', 'hop'), ('nevermind', 'hip', 'hop'), ('accompanied', 'hip', 'hop'), ('flashy', 'hip', 'hop'), ('hip', 'hop', 'copied'), ('hip', 'hop', 'mixtapes'), ('hip', 'hop', 'benefited'), ('hip', 'hop', 'olympics'), ('spectrum', 'hip', 'hop'), ('bnm', 'hip', 'hop'), ('hip', 'hop', 'partly')]\n"
    }
   ],
   "source": [
    "print(top_ngrams(male_giant_comment_string, top_n=50, ngram=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most common adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_adjectives(female_giant_comment_string, num_of_words=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_adjectives(male_giant_comment_string, num_of_words=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Just analyze \"regular English\" words?\n",
    "# TODO: Generate markov chain of how someone would talk about one group versus another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596266487023",
   "display_name": "Python 3.8.3 64-bit ('gendered-discussion': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}